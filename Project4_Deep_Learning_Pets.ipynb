{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UcP0RHTjWP1q"
   },
   "source": [
    "# Practice 8: Deep Learning in Neural Networks\n",
    "\n",
    "Use this notebook as the starting point for the Practice activities.\n",
    "\n",
    "Student Name:    **[  Put your Name Here ]**\n",
    "\n",
    "\n",
    "*Video posted soon.*\n",
    "\n",
    "## Pet Data Fields\n",
    "- PetID - Unique hash ID of pet profile\n",
    "- AdoptionSpeed - Categorical speed of adoption. Lower is faster. This is the value to predict. See below section for more info.\n",
    "- Type - Type of animal (1 = Dog, 2 = Cat)\n",
    "- Name - Name of pet (Empty if not named)\n",
    "- Age - Age of pet when listed, in months\n",
    "- Breed1 - Primary breed of pet (Refer to BreedLabels dictionary)\n",
    "- Breed2 - Secondary breed of pet, if pet is of mixed breed (Refer to BreedLabels dictionary)\n",
    "- Gender - Gender of pet (1 = Male, 2 = Female, 3 = Mixed, if profile represents group of pets)\n",
    "- Color1 - Color 1 of pet (Refer to ColorLabels dictionary)\n",
    "- Color2 - Color 2 of pet (Refer to ColorLabels dictionary)\n",
    "- Color3 - Color 3 of pet (Refer to ColorLabels dictionary)\n",
    "- MaturitySize - Size at maturity (1 = Small, 2 = Medium, 3 = Large, 4 = Extra Large, 0 = Not Specified)\n",
    "- FurLength - Fur length (1 = Short, 2 = Medium, 3 = Long, 0 = Not Specified)\n",
    "- Vaccinated - Pet has been vaccinated (1 = Yes, 2 = No, 3 = Not Sure)\n",
    "- Dewormed - Pet has been dewormed (1 = Yes, 2 = No, 3 = Not Sure)\n",
    "- Sterilized - Pet has been spayed / neutered (1 = Yes, 2 = No, 3 = Not Sure)\n",
    "- Health - Health Condition (1 = Healthy, 2 = Minor Injury, 3 = Serious Injury, 0 = Not Specified)\n",
    "- Quantity - Number of pets represented in profile\n",
    "- Fee - Adoption fee (0 = Free)\n",
    "- State - State location in Malaysia (Refer to StateLabels dictionary)\n",
    "- RescuerID - Unique hash ID of rescuer\n",
    "- VideoAmt - Total uploaded videos for this pet\n",
    "- PhotoAmt - Total uploaded photos for this pet\n",
    "- Description - Profile write-up for this pet. The primary language used is English, with some in Malay or Chinese.\n",
    "### AdoptionSpeed\n",
    "Contestants are required to predict this value. The value is determined by how quickly, if at all, a pet is adopted. The values are determined in the following way: \n",
    "- 0 - Pet was adopted on the same day as it was listed. \n",
    "- 1 - Pet was adopted between 1 and 7 days (1st week) after being listed. \n",
    "- 2 - Pet was adopted between 8 and 30 days (1st month) after being listed. \n",
    "- 3 - Pet was adopted between 31 and 90 days (2nd & 3rd month) after being listed. \n",
    "- 4 - No adoption after 100 days of being listed. (There are no pets in this dataset that waited between 90 and 100 days).\n",
    "\n",
    "### File descriptions\n",
    "- train.csv - Tabular/text data for the training set\n",
    "- train.csv - Tabular/text data for the training set\n",
    "- test.csv - Tabular/text data for the test set\n",
    "- sample_submission.csv - A sample submission file in the correct format\n",
    "- breed_labels.csv - Contains Type, and BreedName for each BreedID. Type 1 is dog, 2 is cat.\n",
    "- color_labels.csv - Contains ColorName for each ColorID\n",
    "- state_labels.csv - Contains StateName for each StateID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KmZ4LSJ7XLR9"
   },
   "source": [
    "# Section 0\n",
    "\n",
    "=== *You must run this section to set up things for any of the sections below * ===\n",
    "### Setting up Python tools\n",
    "\n",
    "\n",
    "\n",
    "We'll use three libraries for this tutorial: \n",
    "- [pandas](http://pandas.pydata.org/) : dataframes for spreadsheet-like data analysis, reading CSV files, time series\n",
    "- [numpy](http://www.numpy.org/) : for multidimensional data and linear algebra tools\n",
    "- [matplotlib](http://matplotlib.org/) : Simple plotting and graphing\n",
    "- [seaborn](http://stanford.edu/~mwaskom/software/seaborn/) : more advanced graphing\n",
    "-  [scikit-learn](https://scikit-learn.org/stable/) : provides many machine learning algorithms and tools to training and test.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2324,
     "status": "ok",
     "timestamp": 1551833242787,
     "user": {
      "displayName": "Thomas Gibbons",
      "photoUrl": "https://lh6.googleusercontent.com/-aKNRGZRXBOQ/AAAAAAAAAAI/AAAAAAAAGk8/tKwL-Nlv8wU/s64/photo.jpg",
      "userId": "00153145788865022523"
     },
     "user_tz": 360
    },
    "id": "RHAUKyWlWQ9L",
    "outputId": "affecdfe-b8d6-432e-f92d-2dc59fd50268"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== This should generate a FutureWaring on Conversion ===== ignore this warning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tgibbons\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# First, we'll import pandas and numpy, two data processing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# We'll also import seaborn and matplot, twp Python graphing libraries\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# Import the needed sklearn libraries\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# The Keras library provides support for neural networks and deep learning\n",
    "print (\"====== This should generate a FutureWaring on Conversion ===== ignore this warning\")\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Lambda, Flatten, LSTM\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# We will turn off some warns in this notebook to make it easier to read for new students\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sTvnB7XwvScZ"
   },
   "source": [
    "## Task 1: Past Kaggle result for Digit Challenge\n",
    "\n",
    "In an eariler activite you created an account at Kaggle,  [www.Kaggle.com](https://www.kaggle.com/) most likely using your CSS email address with the \"Sign up with Google\" option\n",
    "\n",
    "\n",
    "Return to the [Kaggle Digit Recognition challenge](https://www.kaggle.com/c/digit-recognizer) and find the top score for your submissions--click on the \"My Submissions\" tab. \n",
    "\n",
    "What was your top submission previously:  _ _ _ _ _ _ _ _ _ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mEuPVnRDdGpu"
   },
   "source": [
    "# Section 1:  Reducing the Learning Rate\n",
    "=== *You must run Section 0 before this section* ===\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YZ1dW8lJvScd"
   },
   "source": [
    "### Set up the Input and output\n",
    "\n",
    "- Training data: 42,000 images, each 28 x28 pixes, each labeled with the actual digit 0 - 9\n",
    "- Submission data: 28,000 images, each 28 x 28 pixes, not labeled. You must generate predictions for each of these\n",
    "\n",
    "### NOTE: This dataset is somewhat large and loading it may take a minute or two \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9729,
     "status": "ok",
     "timestamp": 1551839068073,
     "user": {
      "displayName": "Thomas Gibbons",
      "photoUrl": "https://lh6.googleusercontent.com/-aKNRGZRXBOQ/AAAAAAAAAAI/AAAAAAAAGk8/tKwL-Nlv8wU/s64/photo.jpg",
      "userId": "00153145788865022523"
     },
     "user_tz": 360
    },
    "id": "Z_gd5XuZvScg",
    "outputId": "ea4b4e8d-3f87-44a5-d1b7-41211e100248"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_kaggle training data shape of 28x28 pixels greyscale:  (42000, 28, 28)\n",
      "X_submit_kaggle submission data shape of 28x28 pixels greyscale: :  (28000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Read data from the actual Kaggle download files stored in a raw file in GitHub\n",
    "url_kaggle_train = 'https://raw.githubusercontent.com/CIS3115-Machine-Learning-Scholastica/CIS3115ML-Units7and8/master/kaggle-digit-recognizer/train.csv'\n",
    "url_kaggle_test = 'https://raw.githubusercontent.com/CIS3115-Machine-Learning-Scholastica/CIS3115ML-Units7and8/master/kaggle-digit-recognizer/test.csv'\n",
    "  \n",
    "train_kaggle = pd.read_csv(url_kaggle_train)\n",
    "# Pull out the labels or output which are saved in first index\n",
    "y_train_kaggle = train_kaggle.iloc[:,0].values.astype('int32')\n",
    "# Convert remaining values to floats\n",
    "X_train_kaggle = (train_kaggle.iloc[:,1:].values).astype('float32')\n",
    "# Read the kaggle test data which is used for submissions\n",
    "X_submit_kaggle = (pd.read_csv(url_kaggle_test).values).astype('float32')\n",
    "#reshape as 28x28 pixel images\n",
    "X_train_kaggle = X_train_kaggle.reshape(X_train_kaggle.shape[0], 28, 28)\n",
    "X_submit_kaggle = X_submit_kaggle.reshape(X_submit_kaggle.shape[0], 28, 28)\n",
    "\n",
    "print (\"X_train_kaggle training data shape of 28x28 pixels greyscale: \" ,X_train_kaggle.shape)\n",
    "print (\"X_submit_kaggle submission data shape of 28x28 pixels greyscale: : \" ,X_submit_kaggle.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "labels_breed = pd.read_csv('breed_labels.csv')\n",
    "labels_state = pd.read_csv('color_labels.csv')\n",
    "labels_color = pd.read_csv('state_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Breed1</th>\n",
       "      <th>Breed2</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Color1</th>\n",
       "      <th>Color2</th>\n",
       "      <th>Color3</th>\n",
       "      <th>MaturitySize</th>\n",
       "      <th>...</th>\n",
       "      <th>Health</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Fee</th>\n",
       "      <th>State</th>\n",
       "      <th>RescuerID</th>\n",
       "      <th>VideoAmt</th>\n",
       "      <th>Description</th>\n",
       "      <th>PetID</th>\n",
       "      <th>PhotoAmt</th>\n",
       "      <th>AdoptionSpeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Nibble</td>\n",
       "      <td>3</td>\n",
       "      <td>299</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>41326</td>\n",
       "      <td>8480853f516546f6cf33aa88cd76c379</td>\n",
       "      <td>0</td>\n",
       "      <td>Nibble is a 3+ month old ball of cuteness. He ...</td>\n",
       "      <td>86e1089a3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>No Name Yet</td>\n",
       "      <td>1</td>\n",
       "      <td>265</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41401</td>\n",
       "      <td>3082c7125d8fb66f7dd4bff4192c8b14</td>\n",
       "      <td>0</td>\n",
       "      <td>I just found it alone yesterday near my apartm...</td>\n",
       "      <td>6296e909a</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Brisco</td>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41326</td>\n",
       "      <td>fa90fa5b1ee11c86938398b60abc32cb</td>\n",
       "      <td>0</td>\n",
       "      <td>Their pregnant mother was dumped by her irresp...</td>\n",
       "      <td>3422e4906</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Miko</td>\n",
       "      <td>4</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>41401</td>\n",
       "      <td>9238e4f44c71a75282e62f7136c6b240</td>\n",
       "      <td>0</td>\n",
       "      <td>Good guard dog, very alert, active, obedience ...</td>\n",
       "      <td>5842f1ff5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Hunter</td>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41326</td>\n",
       "      <td>95481e953f8aed9ec3d16fc4509537e8</td>\n",
       "      <td>0</td>\n",
       "      <td>This handsome yet cute boy is up for adoption....</td>\n",
       "      <td>850a43f90</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Type         Name  Age  Breed1  Breed2  Gender  Color1  Color2  Color3  \\\n",
       "0     2       Nibble    3     299       0       1       1       7       0   \n",
       "1     2  No Name Yet    1     265       0       1       1       2       0   \n",
       "2     1       Brisco    1     307       0       1       2       7       0   \n",
       "3     1         Miko    4     307       0       2       1       2       0   \n",
       "4     1       Hunter    1     307       0       1       1       0       0   \n",
       "\n",
       "   MaturitySize  ...  Health  Quantity  Fee  State  \\\n",
       "0             1  ...       1         1  100  41326   \n",
       "1             2  ...       1         1    0  41401   \n",
       "2             2  ...       1         1    0  41326   \n",
       "3             2  ...       1         1  150  41401   \n",
       "4             2  ...       1         1    0  41326   \n",
       "\n",
       "                          RescuerID  VideoAmt  \\\n",
       "0  8480853f516546f6cf33aa88cd76c379         0   \n",
       "1  3082c7125d8fb66f7dd4bff4192c8b14         0   \n",
       "2  fa90fa5b1ee11c86938398b60abc32cb         0   \n",
       "3  9238e4f44c71a75282e62f7136c6b240         0   \n",
       "4  95481e953f8aed9ec3d16fc4509537e8         0   \n",
       "\n",
       "                                         Description      PetID PhotoAmt  \\\n",
       "0  Nibble is a 3+ month old ball of cuteness. He ...  86e1089a3      1.0   \n",
       "1  I just found it alone yesterday near my apartm...  6296e909a      2.0   \n",
       "2  Their pregnant mother was dumped by her irresp...  3422e4906      7.0   \n",
       "3  Good guard dog, very alert, active, obedience ...  5842f1ff5      8.0   \n",
       "4  This handsome yet cute boy is up for adoption....  850a43f90      3.0   \n",
       "\n",
       "   AdoptionSpeed  \n",
       "0              2  \n",
       "1              0  \n",
       "2              3  \n",
       "3              2  \n",
       "4              2  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train training data shape:  (14993, 5)\n",
      "y_train training data shape:  (14993,)\n"
     ]
    }
   ],
   "source": [
    "X_train = train[['Age','Gender','Health','MaturitySize','FurLength']]\n",
    "X_train.head(5)\n",
    "y_train = train['AdoptionSpeed']\n",
    "print (\"X_train training data shape: \" ,X_train.shape)\n",
    "print (\"y_train training data shape: \" ,y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Health</th>\n",
       "      <th>MaturitySize</th>\n",
       "      <th>FurLength</th>\n",
       "      <th>encodedVaccinated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Gender  Health  MaturitySize  FurLength  encodedVaccinated\n",
       "0    3       1       1             1          1                  0\n",
       "1    1       1       1             2          2                  0\n",
       "2    1       1       1             2          2                  1\n",
       "3    4       2       1             2          1                  1\n",
       "4    1       1       1             2          1                  0\n",
       "5    3       2       1             2          1                  0\n",
       "6   12       1       1             2          3                  0\n",
       "7    0       2       1             2          1                  0\n",
       "8    2       2       1             2          2                  0\n",
       "9   12       2       1             2          2                  0"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vaccinated - Pet has been vaccinated (1 = Yes, 2 = No, 3 = Not Sure)\n",
    "#encodedVaccinated = train[['Vaccinated']] \n",
    "def fixVac( value ):\n",
    "    if value > 1: return 0\n",
    "    else: return value\n",
    "\n",
    "#train['encodedVaccinated'] = list(map(lambda a: 0 if (a>1) else a,train['Vaccinated']))\n",
    "X_train['encodedVaccinated'] = list(map(fixVac,train['Vaccinated']))\n",
    "\n",
    "X_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Health</th>\n",
       "      <th>MaturitySize</th>\n",
       "      <th>FurLength</th>\n",
       "      <th>encodedVaccinated</th>\n",
       "      <th>encodedColor1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Gender  Health  MaturitySize  FurLength  encodedVaccinated  \\\n",
       "0    3       1       1             1          1                  0   \n",
       "1    1       1       1             2          2                  0   \n",
       "2    1       1       1             2          2                  1   \n",
       "3    4       2       1             2          1                  1   \n",
       "4    1       1       1             2          1                  0   \n",
       "5    3       2       1             2          1                  0   \n",
       "6   12       1       1             2          3                  0   \n",
       "7    0       2       1             2          1                  0   \n",
       "8    2       2       1             2          2                  0   \n",
       "9   12       2       1             2          2                  0   \n",
       "\n",
       "                              encodedColor1  \n",
       "0  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "1  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "2  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "3  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "4  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "5  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]  \n",
       "6  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "7  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "8  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]  \n",
       "9  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encodedColor1 = to_categorical( train['Color1'] )\n",
    "X_train['encodedColor1'] = encodedColor1.tolist()\n",
    "#trainP = np.concatenate((trainP,encodedColor1), axis=1)\n",
    "X_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train training data shape:  (14993, 7)\n",
      "y_train training data shape:  (14993,)\n"
     ]
    }
   ],
   "source": [
    "print (\"X_train training data shape: \" ,X_train.shape)\n",
    "print (\"y_train training data shape: \" ,y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into 80% for training and 10% for testing out the models\n",
    "X_train, X_test, y_train_num, y_test_num = train_test_split(X_train, y_train, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Health</th>\n",
       "      <th>MaturitySize</th>\n",
       "      <th>FurLength</th>\n",
       "      <th>encodedVaccinated</th>\n",
       "      <th>encodedColor1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1417</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13656</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3585</th>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8771</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6823</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2515</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7987</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4505</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7389</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7688</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10374</th>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9747</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2869</th>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6319</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5783</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6634</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11759</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13972</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2827</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12594</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3780</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9073</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9085</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11098</th>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13994</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12340</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9297</th>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14944</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9435</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12066</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11233</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11904</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12544</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5345</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7788</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8328</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8493</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2606</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1378</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6957</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7881</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8960</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11656</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9957</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13701</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14557</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4294</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8526</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4883</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13211</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2709</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12177</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2287</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5005</th>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7933</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Age  Gender  Health  MaturitySize  FurLength  encodedVaccinated  \\\n",
       "1417     3       2       1             3          1                  1   \n",
       "13656   12       2       1             1          1                  1   \n",
       "3585    24       2       1             2          1                  0   \n",
       "8771     4       2       1             2          2                  0   \n",
       "6823     2       2       1             1          1                  0   \n",
       "2515     2       1       1             2          1                  1   \n",
       "7987     5       2       1             2          1                  1   \n",
       "416      2       1       1             1          1                  0   \n",
       "4505     3       1       1             2          1                  0   \n",
       "7389     2       2       1             2          1                  0   \n",
       "7688     1       3       1             2          1                  0   \n",
       "10374   60       2       1             1          1                  0   \n",
       "9747    12       1       1             3          1                  0   \n",
       "2869    42       1       1             2          1                  0   \n",
       "6319     5       2       1             2          1                  1   \n",
       "5783     3       2       1             2          1                  1   \n",
       "6634     2       3       1             2          2                  1   \n",
       "11759    1       2       1             2          2                  1   \n",
       "13972    2       2       1             1          1                  0   \n",
       "2827    14       1       1             2          2                  0   \n",
       "12594    1       3       1             2          2                  0   \n",
       "3780    10       1       1             2          1                  1   \n",
       "9073     1       3       1             2          2                  0   \n",
       "9085     1       2       1             2          1                  1   \n",
       "11098   24       2       1             2          1                  1   \n",
       "13994    3       3       1             2          2                  0   \n",
       "12340   10       2       1             1          3                  1   \n",
       "9297    18       2       1             2          1                  1   \n",
       "598      1       3       1             2          2                  0   \n",
       "14944    3       2       1             1          2                  0   \n",
       "...    ...     ...     ...           ...        ...                ...   \n",
       "9435     3       1       1             2          1                  1   \n",
       "12066    1       3       1             1          2                  0   \n",
       "11233   12       2       1             2          2                  0   \n",
       "11904    9       2       1             2          1                  1   \n",
       "12544    1       2       1             2          2                  0   \n",
       "5345     3       2       1             2          1                  0   \n",
       "7788     2       2       1             1          1                  0   \n",
       "8328     5       2       1             1          3                  1   \n",
       "2439     3       1       1             2          2                  0   \n",
       "8493    24       1       1             2          2                  1   \n",
       "2606     5       2       1             1          3                  0   \n",
       "1378     2       2       1             2          1                  0   \n",
       "188      4       2       1             2          1                  0   \n",
       "6957     3       2       1             1          1                  0   \n",
       "7881     3       2       1             2          2                  1   \n",
       "8960    12       2       1             1          1                  0   \n",
       "11656   24       1       2             2          2                  0   \n",
       "9957     3       2       1             2          1                  0   \n",
       "13701    2       2       1             2          2                  1   \n",
       "14557    1       3       1             3          2                  0   \n",
       "4294     2       1       1             2          1                  0   \n",
       "8526     2       2       1             2          1                  1   \n",
       "4883     2       1       1             1          2                  0   \n",
       "13211    2       2       1             2          1                  1   \n",
       "1983     1       1       1             2          1                  0   \n",
       "2709     3       2       1             1          1                  1   \n",
       "12177    2       2       1             2          2                  0   \n",
       "2287     4       1       1             1          1                  0   \n",
       "5005    24       2       1             2          2                  0   \n",
       "7933     2       1       1             2          1                  0   \n",
       "\n",
       "                                  encodedColor1  \n",
       "1417   [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "13656  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "3585   [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "8771   [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]  \n",
       "6823   [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "2515   [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]  \n",
       "7987   [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]  \n",
       "416    [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "4505   [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "7389   [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "7688   [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "10374  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "9747   [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "2869   [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "6319   [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "5783   [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]  \n",
       "6634   [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "11759  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "13972  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "2827   [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "12594  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "3780   [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "9073   [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "9085   [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "11098  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "13994  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "12340  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "9297   [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "598    [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "14944  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "...                                         ...  \n",
       "9435   [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "12066  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "11233  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "11904  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "12544  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "5345   [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "7788   [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "8328   [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "2439   [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "8493   [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "2606   [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "1378   [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "188    [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "6957   [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "7881   [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "8960   [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "11656  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]  \n",
       "9957   [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "13701  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]  \n",
       "14557  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "4294   [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "8526   [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "4883   [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "13211  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "1983   [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "2709   [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "12177  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "2287   [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "5005   [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "7933   [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "\n",
       "[1500 rows x 7 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 1, 1, ..., 1, 0,\n",
       "        list([0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])],\n",
       "       [1, 1, 1, ..., 2, 0,\n",
       "        list([0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])],\n",
       "       [1, 1, 1, ..., 2, 1,\n",
       "        list([0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0])],\n",
       "       ...,\n",
       "       [2, 3, 1, ..., 2, 0,\n",
       "        list([0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0])],\n",
       "       [9, 2, 1, ..., 1, 1,\n",
       "        list([0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0])],\n",
       "       [1, 1, 1, ..., 1, 0,\n",
       "        list([0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0])]], dtype=object)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainP = trainNN.values\n",
    "trainP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "encodedColor1 = to_categorical( train['Color1'] )\n",
    "print(encodedColor1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainP = np.concatenate((trainP,encodedColor1), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data shape:  (14993, 24)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Breed1</th>\n",
       "      <th>Breed2</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Color1</th>\n",
       "      <th>Color2</th>\n",
       "      <th>Color3</th>\n",
       "      <th>MaturitySize</th>\n",
       "      <th>...</th>\n",
       "      <th>Health</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Fee</th>\n",
       "      <th>State</th>\n",
       "      <th>RescuerID</th>\n",
       "      <th>VideoAmt</th>\n",
       "      <th>Description</th>\n",
       "      <th>PetID</th>\n",
       "      <th>PhotoAmt</th>\n",
       "      <th>AdoptionSpeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Nibble</td>\n",
       "      <td>3</td>\n",
       "      <td>299</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>41326</td>\n",
       "      <td>8480853f516546f6cf33aa88cd76c379</td>\n",
       "      <td>0</td>\n",
       "      <td>Nibble is a 3+ month old ball of cuteness. He ...</td>\n",
       "      <td>86e1089a3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>No Name Yet</td>\n",
       "      <td>1</td>\n",
       "      <td>265</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41401</td>\n",
       "      <td>3082c7125d8fb66f7dd4bff4192c8b14</td>\n",
       "      <td>0</td>\n",
       "      <td>I just found it alone yesterday near my apartm...</td>\n",
       "      <td>6296e909a</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Brisco</td>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41326</td>\n",
       "      <td>fa90fa5b1ee11c86938398b60abc32cb</td>\n",
       "      <td>0</td>\n",
       "      <td>Their pregnant mother was dumped by her irresp...</td>\n",
       "      <td>3422e4906</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Miko</td>\n",
       "      <td>4</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>41401</td>\n",
       "      <td>9238e4f44c71a75282e62f7136c6b240</td>\n",
       "      <td>0</td>\n",
       "      <td>Good guard dog, very alert, active, obedience ...</td>\n",
       "      <td>5842f1ff5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Hunter</td>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41326</td>\n",
       "      <td>95481e953f8aed9ec3d16fc4509537e8</td>\n",
       "      <td>0</td>\n",
       "      <td>This handsome yet cute boy is up for adoption....</td>\n",
       "      <td>850a43f90</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41326</td>\n",
       "      <td>22fe332bf9c924d4718005891c63fbed</td>\n",
       "      <td>0</td>\n",
       "      <td>This is a stray kitten that came to my house. ...</td>\n",
       "      <td>d24c30b4b</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>BULAT</td>\n",
       "      <td>12</td>\n",
       "      <td>264</td>\n",
       "      <td>264</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>300</td>\n",
       "      <td>41326</td>\n",
       "      <td>1e0b5a458b5b77f5af581d57ebf570b3</td>\n",
       "      <td>0</td>\n",
       "      <td>anyone within the area of ipoh or taiping who ...</td>\n",
       "      <td>1caa6fcdb</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>Siu Pak &amp; Her 6 Puppies</td>\n",
       "      <td>0</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>41326</td>\n",
       "      <td>1fba5f6e5480946254590d48f9c5198d</td>\n",
       "      <td>0</td>\n",
       "      <td>Siu Pak just give birth on 13/6/10 to 6puppies...</td>\n",
       "      <td>97aa9eeac</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>265</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41326</td>\n",
       "      <td>d8af7afece71334473575c9f70daf00d</td>\n",
       "      <td>0</td>\n",
       "      <td>healthy and active, feisty kitten found in nei...</td>\n",
       "      <td>c06d167ca</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>Kitty</td>\n",
       "      <td>12</td>\n",
       "      <td>265</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41326</td>\n",
       "      <td>1f3f36e4b18e94855b3e88af0852fdc4</td>\n",
       "      <td>0</td>\n",
       "      <td>Very manja and gentle stray cat found, we woul...</td>\n",
       "      <td>7a0942d61</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>Bear</td>\n",
       "      <td>2</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41401</td>\n",
       "      <td>9238e4f44c71a75282e62f7136c6b240</td>\n",
       "      <td>0</td>\n",
       "      <td>For serious adopter, please do sms or call for...</td>\n",
       "      <td>8b693ca84</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>Kali</td>\n",
       "      <td>3</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>41326</td>\n",
       "      <td>a9caef3f98e67bfac9093cca79e20b93</td>\n",
       "      <td>0</td>\n",
       "      <td>Kali is a super playful kitten who is on the g...</td>\n",
       "      <td>8e76c8e39</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>Peanut</td>\n",
       "      <td>2</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41326</td>\n",
       "      <td>db784cbcf321e1d8856b312638b94113</td>\n",
       "      <td>0</td>\n",
       "      <td>Peanut was an abused puppy until he was rescue...</td>\n",
       "      <td>aaedd873d</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>2 Mths Old Cute Kitties</td>\n",
       "      <td>2</td>\n",
       "      <td>265</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>41326</td>\n",
       "      <td>2c118b2a1d1b4cf1f735089c7c0a07c0</td>\n",
       "      <td>0</td>\n",
       "      <td>Hi Pet Lovers! This is my first posting and I ...</td>\n",
       "      <td>4a9793dfb</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>Lost Dog</td>\n",
       "      <td>3</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41401</td>\n",
       "      <td>b609c40c6c840db208b149a19b856f86</td>\n",
       "      <td>0</td>\n",
       "      <td>Lost Dog Found (Bandar Menjalara, Kepongï¼Taman...</td>\n",
       "      <td>c02be41e6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>Max</td>\n",
       "      <td>78</td>\n",
       "      <td>218</td>\n",
       "      <td>205</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41326</td>\n",
       "      <td>39112c637c80a6055e8ec544416abffe</td>\n",
       "      <td>0</td>\n",
       "      <td>We moved out of our apartment to a landed home...</td>\n",
       "      <td>1fd342e17</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>Brownie</td>\n",
       "      <td>6</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41326</td>\n",
       "      <td>58e3aa0b4b78e8879f81774ede0646fe</td>\n",
       "      <td>0</td>\n",
       "      <td>to be spayed on /12 adorable &amp; friendly</td>\n",
       "      <td>b38a74866</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>Blackie</td>\n",
       "      <td>8</td>\n",
       "      <td>307</td>\n",
       "      <td>307</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>41330</td>\n",
       "      <td>4e3dec1544d1407fce5d65fd0f037e26</td>\n",
       "      <td>0</td>\n",
       "      <td>shes active... she can obey wht command that u...</td>\n",
       "      <td>f9d07d5fa</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>2</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41401</td>\n",
       "      <td>9238e4f44c71a75282e62f7136c6b240</td>\n",
       "      <td>0</td>\n",
       "      <td>This cutie dumped by it's owner at the market ...</td>\n",
       "      <td>1c92ce464</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>41326</td>\n",
       "      <td>b752f78276215f44581eeb6eea1e63bc</td>\n",
       "      <td>0</td>\n",
       "      <td>Birth Date: Oct 30th Kitty 1, Melly -Female Sa...</td>\n",
       "      <td>b10e7605a</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Type                     Name  Age  Breed1  Breed2  Gender  Color1  \\\n",
       "0      2                   Nibble    3     299       0       1       1   \n",
       "1      2              No Name Yet    1     265       0       1       1   \n",
       "2      1                   Brisco    1     307       0       1       2   \n",
       "3      1                     Miko    4     307       0       2       1   \n",
       "4      1                   Hunter    1     307       0       1       1   \n",
       "5      2                      NaN    3     266       0       2       5   \n",
       "6      2                    BULAT   12     264     264       1       1   \n",
       "7      1  Siu Pak & Her 6 Puppies    0     307       0       2       1   \n",
       "8      2                      NaN    2     265       0       2       6   \n",
       "9      2                    Kitty   12     265       0       2       1   \n",
       "10     1                     Bear    2     307       0       1       1   \n",
       "11     2                     Kali    3     264       0       2       1   \n",
       "12     1                   Peanut    2     307       0       1       2   \n",
       "13     2  2 Mths Old Cute Kitties    2     265       0       3       1   \n",
       "14     1                 Lost Dog    3     307       0       2       2   \n",
       "15     1                      Max   78     218     205       1       1   \n",
       "16     2                  Brownie    6     266       0       2       2   \n",
       "17     1                  Blackie    8     307     307       2       2   \n",
       "18     1                   Beauty    2     307       0       2       1   \n",
       "19     2                      NaN    1     266       0       3       1   \n",
       "\n",
       "    Color2  Color3  MaturitySize  ...  Health  Quantity  Fee  State  \\\n",
       "0        7       0             1  ...       1         1  100  41326   \n",
       "1        2       0             2  ...       1         1    0  41401   \n",
       "2        7       0             2  ...       1         1    0  41326   \n",
       "3        2       0             2  ...       1         1  150  41401   \n",
       "4        0       0             2  ...       1         1    0  41326   \n",
       "5        6       0             2  ...       1         1    0  41326   \n",
       "6        0       0             2  ...       1         1  300  41326   \n",
       "7        2       7             2  ...       1         6    0  41326   \n",
       "8        0       0             2  ...       1         1    0  41326   \n",
       "9        7       0             2  ...       1         1    0  41326   \n",
       "10       2       7             2  ...       1         1    0  41401   \n",
       "11       2       5             3  ...       1         1   50  41326   \n",
       "12       5       6             2  ...       1         1    0  41326   \n",
       "13       6       7             1  ...       1         7    0  41326   \n",
       "14       5       7             2  ...       1         1    0  41401   \n",
       "15       7       0             2  ...       1         1    0  41326   \n",
       "16       0       0             1  ...       1         1    0  41326   \n",
       "17       0       0             2  ...       1         1   10  41330   \n",
       "18       0       0             2  ...       1         1    0  41401   \n",
       "19       2       7             1  ...       1         5    0  41326   \n",
       "\n",
       "                           RescuerID  VideoAmt  \\\n",
       "0   8480853f516546f6cf33aa88cd76c379         0   \n",
       "1   3082c7125d8fb66f7dd4bff4192c8b14         0   \n",
       "2   fa90fa5b1ee11c86938398b60abc32cb         0   \n",
       "3   9238e4f44c71a75282e62f7136c6b240         0   \n",
       "4   95481e953f8aed9ec3d16fc4509537e8         0   \n",
       "5   22fe332bf9c924d4718005891c63fbed         0   \n",
       "6   1e0b5a458b5b77f5af581d57ebf570b3         0   \n",
       "7   1fba5f6e5480946254590d48f9c5198d         0   \n",
       "8   d8af7afece71334473575c9f70daf00d         0   \n",
       "9   1f3f36e4b18e94855b3e88af0852fdc4         0   \n",
       "10  9238e4f44c71a75282e62f7136c6b240         0   \n",
       "11  a9caef3f98e67bfac9093cca79e20b93         0   \n",
       "12  db784cbcf321e1d8856b312638b94113         0   \n",
       "13  2c118b2a1d1b4cf1f735089c7c0a07c0         0   \n",
       "14  b609c40c6c840db208b149a19b856f86         0   \n",
       "15  39112c637c80a6055e8ec544416abffe         0   \n",
       "16  58e3aa0b4b78e8879f81774ede0646fe         0   \n",
       "17  4e3dec1544d1407fce5d65fd0f037e26         0   \n",
       "18  9238e4f44c71a75282e62f7136c6b240         0   \n",
       "19  b752f78276215f44581eeb6eea1e63bc         0   \n",
       "\n",
       "                                          Description      PetID PhotoAmt  \\\n",
       "0   Nibble is a 3+ month old ball of cuteness. He ...  86e1089a3      1.0   \n",
       "1   I just found it alone yesterday near my apartm...  6296e909a      2.0   \n",
       "2   Their pregnant mother was dumped by her irresp...  3422e4906      7.0   \n",
       "3   Good guard dog, very alert, active, obedience ...  5842f1ff5      8.0   \n",
       "4   This handsome yet cute boy is up for adoption....  850a43f90      3.0   \n",
       "5   This is a stray kitten that came to my house. ...  d24c30b4b      2.0   \n",
       "6   anyone within the area of ipoh or taiping who ...  1caa6fcdb      3.0   \n",
       "7   Siu Pak just give birth on 13/6/10 to 6puppies...  97aa9eeac      9.0   \n",
       "8   healthy and active, feisty kitten found in nei...  c06d167ca      6.0   \n",
       "9   Very manja and gentle stray cat found, we woul...  7a0942d61      2.0   \n",
       "10  For serious adopter, please do sms or call for...  8b693ca84      7.0   \n",
       "11  Kali is a super playful kitten who is on the g...  8e76c8e39      2.0   \n",
       "12  Peanut was an abused puppy until he was rescue...  aaedd873d      1.0   \n",
       "13  Hi Pet Lovers! This is my first posting and I ...  4a9793dfb      1.0   \n",
       "14  Lost Dog Found (Bandar Menjalara, Kepongï¼Taman...  c02be41e6      2.0   \n",
       "15  We moved out of our apartment to a landed home...  1fd342e17      2.0   \n",
       "16            to be spayed on /12 adorable & friendly  b38a74866      1.0   \n",
       "17  shes active... she can obey wht command that u...  f9d07d5fa      2.0   \n",
       "18  This cutie dumped by it's owner at the market ...  1c92ce464      8.0   \n",
       "19  Birth Date: Oct 30th Kitty 1, Melly -Female Sa...  b10e7605a      1.0   \n",
       "\n",
       "    AdoptionSpeed  \n",
       "0               2  \n",
       "1               0  \n",
       "2               3  \n",
       "3               2  \n",
       "4               2  \n",
       "5               2  \n",
       "6               1  \n",
       "7               3  \n",
       "8               1  \n",
       "9               4  \n",
       "10              1  \n",
       "11              1  \n",
       "12              2  \n",
       "13              1  \n",
       "14              2  \n",
       "15              4  \n",
       "16              3  \n",
       "17              4  \n",
       "18              2  \n",
       "19              4  \n",
       "\n",
       "[20 rows x 24 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (\"training data shape: \" ,train.shape)\n",
    "train.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "azNaomGavScs"
   },
   "source": [
    "## Set up the data\n",
    "\n",
    "**Scale Data:** Neural Networks work best with the inputs are between 0 and +1, but the grayscale images have pixel values between 0 and 255. So, each pixel value is divided by 255 to scale it.\n",
    "\n",
    "**Reformatting: **Above we reformatted the data into 28x28 pixel arrays so we could display it. Now we are converting it back to a single list of 784 pixels. ( 28 x 28 = 784)\n",
    "\n",
    "**Split the Data:** The training data is split with 90% used for training and 10% used for testing.\n",
    "\n",
    "**One-Hot Encoding:** A one-hot encoding is a list which is 0 in most positions, and 1 in a single positions.  In this case, the nth digit will be represented as a vector which is 1 in the nth dimension.\n",
    "\n",
    "- For example, 3 would be [0,0,0,1,0,0,0,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eIQ8a0whvScx"
   },
   "outputs": [],
   "source": [
    "\n",
    "input_Size = 28 * 28    # images are 28 x 28 pixels or 784 pixels\n",
    "output_Size = 10\n",
    "\n",
    "# Normalize the data so values are between 0 and 1 instead of between 0 and 255\n",
    "X_train_kaggle = X_train_kaggle / 255\n",
    "X_submit_kaggle = X_submit_kaggle / 255\n",
    "\n",
    "#reshape for dense-only inputs\n",
    "train_size = X_train_kaggle.shape[0]\n",
    "submit_size = X_submit_kaggle.shape[0]\n",
    "X_train_kaggle = X_train_kaggle.reshape(train_size, 28 * 28)\n",
    "X_submit_kaggle = X_submit_kaggle.reshape(submit_size, 28 * 28)\n",
    "\n",
    "# Split the data into 80% for training and 10% for testing out the models\n",
    "X_train, X_test, y_train_num, y_test_num = train_test_split(X_train_kaggle, y_train_kaggle, test_size=0.1)\n",
    "\n",
    "# A one-hot encoding is a list which is 0 in most positions, and 1 in a single positions. \n",
    "# In this case, the nth digit will be represented as a vector which is 1 in the nth dimension.\n",
    "# For example, 3 would be [0,0,0,1,0,0,0,0,0,0].\n",
    "y_train = np_utils.to_categorical(y_train_num, output_Size)\n",
    "y_test = np_utils.to_categorical(y_test_num, output_Size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 469,
     "status": "ok",
     "timestamp": 1551839165654,
     "user": {
      "displayName": "Thomas Gibbons",
      "photoUrl": "https://lh6.googleusercontent.com/-aKNRGZRXBOQ/AAAAAAAAAAI/AAAAAAAAGk8/tKwL-Nlv8wU/s64/photo.jpg",
      "userId": "00153145788865022523"
     },
     "user_tz": 360
    },
    "id": "TdY9eRGavSc5",
    "outputId": "d4812244-1173-4c48-d9db-87d958aace2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train training data shape of 28x28 pixels greyscale:  (37800, 784)\n",
      "X_test submission data shape of 28x28 pixels greyscale: :  (4200, 784)\n",
      "y_train training data shape of 28x28 pixels greyscale:  (37800, 10)\n",
      "y_test submission data shape of 28x28 pixels greyscale: :  (4200, 10)\n"
     ]
    }
   ],
   "source": [
    "print (\"X_train training data shape of 28x28 pixels greyscale: \" ,X_train.shape)\n",
    "print (\"X_test submission data shape of 28x28 pixels greyscale: : \" ,X_test.shape)\n",
    "\n",
    "print (\"y_train training data shape of 28x28 pixels greyscale: \" ,y_train.shape)\n",
    "print (\"y_test submission data shape of 28x28 pixels greyscale: : \" ,y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hwoi3GqJvSdG"
   },
   "source": [
    "## Neural Network\n",
    "\n",
    "The following code sets up a sequential, four layer neural network. Sequential means that each layer is connected to the layer listed before it:\n",
    "- Input layer: 784 pixels (28x28) used as input values\n",
    "- Hidden layer 1: 20 units using Rectified Linear Units (relu)\n",
    "- Hidden layer 2: 10 units using Rectified Linear Units (relu)\n",
    "- Output  layer: 10 units using softmax to predict the correct digit between 0 and 9\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qaV6VT-66iAf"
   },
   "source": [
    "## Task 2: Deeper Networks\n",
    "\n",
    "As describe above, the network below has an input layer, 2 hidden layers, and on output layer. Modify the network by adding at least one more hidden layer. Also consider making the hidden layers larger.\n",
    "\n",
    "One possibly configuration would be:\n",
    "\n",
    "```\n",
    "DigitNN = Sequential()\n",
    "DigitNN.add(Dense(50, activation='relu', input_dim=(input_Size)))\n",
    "DigitNN.add(Dense(40, activation='relu'))\n",
    "DigitNN.add(Dense(30, activation='relu'))\n",
    "DigitNN.add(Dense(20, activation='relu'))\n",
    "DigitNN.add(Dense(output_Size, activation='softmax'))\n",
    "```\n",
    "\n",
    "Though you should try your own configuration. We will eventually look at networks of 50+ layers, but for now I suggest you limit yourself to 3-5 hidden layers. \n",
    "\n",
    "\n",
    "*Note: You should not change the input or output layers, they are fixed by our problem definition*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M1H9GVNvvSdM"
   },
   "outputs": [],
   "source": [
    "# Set up the Neural Network\n",
    "input_Size = 28 * 28    # images are 28 x 28 pixels or 784 pixels\n",
    "output_Size = 10\n",
    "\n",
    "DigitNN = Sequential()\n",
    "DigitNN.add(Dense(50, activation='relu', input_dim=(input_Size)))\n",
    "DigitNN.add(Dense(40, activation='relu'))\n",
    "DigitNN.add(Dropout(0.5))\n",
    "DigitNN.add(Dense(30, activation='relu'))\n",
    "DigitNN.add(Dense(20, activation='relu'))\n",
    "DigitNN.add(Dense(output_Size, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pJ42A7Pj8bZO"
   },
   "source": [
    "## Task 5: Fighting Overfitting (Please do Tasks 3 and 4 below first)\n",
    "\n",
    "When out network gets large enough and our training refined, our network can learn to memorize all the input features. In these cases our prediction accuracy on the training data may reach 100%. But our test accuracy might be lower, say 94%. \n",
    "\n",
    "This is called [Overfitting](https://en.wikipedia.org/wiki/Overfitting). The model has memorized the training data, but not generalize the rules enough to predict new inputs. For more information see [Overfitting in Machine Learning: What It Is and How to Prevent It](https://elitedatascience.com/overfitting-in-machine-learning)\n",
    "\n",
    "The network only learns when there is a mistake between what the model predicts and what it is suppose to predict. If the model is 100% accurate in training, it is not making any mistakes and so not learning or changing the weights at all.\n",
    "\n",
    "One way to prevent overfitting is to introduce some \"noise\" into the training. One way researcher have found helpful is to randomly skip certain weights when updating a neuron. Keras can do this with a [dropout layer](https://keras.io/layers/core/). \n",
    "\n",
    "### Question 1: Do you have Overfitting?\n",
    "\n",
    "After adding more layers to your network and reducing the Learning Rate, does you model overfit the data? That is, does it work really well on the training data, but not so well on the testing data?\n",
    "\n",
    "### Question 2: Try some Dropout layers\n",
    "\n",
    "Add one or more Dropout layers to your network. The following code adds a Dropout layer between two hidden layers that will randomly ignote 50% of the weights each time.\n",
    "\n",
    "```\n",
    "DigitNN.add(Dense(40, activation='relu'))\n",
    "DigitNN.add(Dropout(0.5))\n",
    "DigitNN.add(Dense(30, activation='relu'))\n",
    "```\n",
    "Add one or more Dropout(0.5) layers to your network. Train it and describe how it performs.\n",
    "\n",
    "### Question 3: Try lower Dropout rates\n",
    "\n",
    "Try a lower dropout rate such as, Dropout(0.1), and retrain the network. Describe how it performs.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OkBAUTdjvSdc"
   },
   "source": [
    "## Compile Neural Network\n",
    "\n",
    "This builds the Neural network. You must specify \n",
    "- optimizer = 'adam' is a common gradient decent method for changing the wieghts during training\n",
    "- loss =  'categorical_crossentropy' is used when you have a number of distinct categories and items can only be in one category.\n",
    "- metrics = 'accuracy' will output the accuracy of the classification, the percent of time the network gets the classification correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dWuDYGv6vSdf"
   },
   "outputs": [],
   "source": [
    "# Compile neural network model\n",
    "DigitNN.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LT2ZSVeXvSdo"
   },
   "source": [
    "## Train the Neural Network\n",
    "\n",
    "This will run all 37800 training images through the network and update the weights. \n",
    "\n",
    "- epochs = 10 means to run the training 10 times. \n",
    "- Performance measues:\n",
    " - loss: is a measurement of how far the outputs are from the desired outputs. This should get smaller over time.\n",
    " - acc: is the prediction accuracy as a percent so 0.67 means the model predicts the correct flower 67% of the time. \n",
    " - val_loss: the loss calculated using the testing flowers rather than the training flowers.\n",
    " - val_acc: the accuracy calculated using the testing flowers rather than the training flowers.\n",
    " \n",
    " \n",
    "### Note: This is a large data set and training will be slow. This might take a couple of minutes to run. \n",
    "\n",
    "This is why we are only using 10 epochs initially"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zxtu22VA2k-T"
   },
   "source": [
    "## Task 3: Reducing the Learning Rate\n",
    "\n",
    "### Learning Rate\n",
    "\n",
    "The Learning Rate determines how much the weights in a neural network are changed during training. When the Learning Rate is set correctly, the network weights are changed a little bit for each input--in our case for each digit image. These slight adjustments from each digit image allow the network to learn all the weights over a long time.\n",
    "\n",
    "For more on the Learning Rate, see [Understanding Learning Rates and How It Improves Performance in Deep Learning](https://towardsdatascience.com/understanding-learning-rates-and-how-it-improves-performance-in-deep-learning-d0d4059c1c10)\n",
    "\n",
    "### Learning Too Fast\n",
    "If the learning rate is too high, when the network is trained on an image of a \"4\" it may change the weights too much and erase the weight changes for the \"3\". The network will learn too fast causing each new image learned to degrade the performance on past images.  \n",
    "\n",
    "### Learning Too Slow\n",
    "\n",
    "If the Learning Rate is too low, the network is learn very slowly. But long training times can compensate for this, but the network may get stuck in \"local minima\" which are places where any small weight change does not improve the model, but a larger weight change would. \n",
    "\n",
    "Imagine you are in a mountain valley where walking in any direction goes up hill. You may be able to go down hill again if you first go uphill for a short while.\n",
    "![alt text](https://i.stack.imgur.com/rPx0Q.png)\n",
    "\n",
    "### Reducing the Learning Rate over time\n",
    "\n",
    "Keras uses a feature named Callbacks to adjust the learning rate as needed. See the documentation for\n",
    "[ReduceLROnPlateau](https://keras.io/callbacks/#reducelronplateau). Run the code cells below to setup the neural network until you get to Task 2 below where you will implement learning rate reduction\n",
    "\n",
    "The code below defines a callback,  learning_rate_reduction, which will automatically reduce the learning rate at certain times. Answer the following questions using the documentation for\n",
    "[ReduceLROnPlateau](https://keras.io/callbacks/#reducelronplateau). \n",
    "\n",
    "### Question 1: What does the \"patience\" parameter control?\n",
    "\n",
    "### Question 2: How much does the Learning Rate get reduced each time?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U-k7Y9H-2wUr"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='accuracy', \n",
    "                                            patience=3, \n",
    "                                            verbose=2, \n",
    "                                            factor=0.3, \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P2S2jGn338I3"
   },
   "source": [
    "## Task 4: Other Callbacks\n",
    "\n",
    "Since we just learned about the ReduceLROnPlateau callback, let's also look at two others that are commonly used.\n",
    "\n",
    "### Question1: What does the [EarlyStopping callback](https://keras.io/callbacks/#earlystopping) do?\n",
    "\n",
    "\n",
    "### Question 2: What does the [ModelCheckpoint callback](https://keras.io/callbacks/#modelcheckpoint) do?\n",
    "\n",
    "### Question 3: Which callbacks are being used? \n",
    "\n",
    "Look at the code two cells below where `DigitNN.fit()` is called. What callbacks are listed to be used when fit() is called?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iir-dKffvSd3"
   },
   "outputs": [],
   "source": [
    "\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "\n",
    "early_stops = EarlyStopping(monitor='accuracy', \n",
    "                            min_delta=0, \n",
    "                            patience=6, \n",
    "                            verbose=2, \n",
    "                            mode='auto')\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath = 'cis3115_MNIST.{epoch:02d}-{accuracy:.6f}.hdf5',\n",
    "                               verbose=2,\n",
    "                               save_best_only=True, \n",
    "                               save_weights_only = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3590
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 234031,
     "status": "ok",
     "timestamp": 1551836848193,
     "user": {
      "displayName": "Thomas Gibbons",
      "photoUrl": "https://lh6.googleusercontent.com/-aKNRGZRXBOQ/AAAAAAAAAAI/AAAAAAAAGk8/tKwL-Nlv8wU/s64/photo.jpg",
      "userId": "00153145788865022523"
     },
     "user_tz": 360
    },
    "id": "pMeiCJoZvSd6",
    "outputId": "5b3fb0a9-439b-4f5e-a746-8ddba65a5177"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/100\n",
      "37800/37800 [==============================] - 3s 73us/step - loss: 0.6206 - acc: 0.8097 - val_loss: 0.2426 - val_acc: 0.9286\n",
      "Epoch 2/100\n",
      "37800/37800 [==============================] - 2s 62us/step - loss: 0.3312 - acc: 0.9014 - val_loss: 0.2020 - val_acc: 0.9414\n",
      "Epoch 3/100\n",
      "37800/37800 [==============================] - 2s 62us/step - loss: 0.2744 - acc: 0.9190 - val_loss: 0.1656 - val_acc: 0.9524\n",
      "Epoch 4/100\n",
      "37800/37800 [==============================] - 2s 61us/step - loss: 0.2397 - acc: 0.9278 - val_loss: 0.1552 - val_acc: 0.9533\n",
      "Epoch 5/100\n",
      "37800/37800 [==============================] - 2s 61us/step - loss: 0.2186 - acc: 0.9349 - val_loss: 0.1381 - val_acc: 0.9590\n",
      "Epoch 6/100\n",
      "37800/37800 [==============================] - 2s 61us/step - loss: 0.2038 - acc: 0.9390 - val_loss: 0.1362 - val_acc: 0.9595\n",
      "Epoch 7/100\n",
      "37800/37800 [==============================] - 2s 61us/step - loss: 0.1906 - acc: 0.9432 - val_loss: 0.1315 - val_acc: 0.9590\n",
      "Epoch 8/100\n",
      "37800/37800 [==============================] - 2s 61us/step - loss: 0.1816 - acc: 0.9448 - val_loss: 0.1244 - val_acc: 0.9631\n",
      "Epoch 9/100\n",
      "37800/37800 [==============================] - 2s 61us/step - loss: 0.1693 - acc: 0.9489 - val_loss: 0.1258 - val_acc: 0.9640\n",
      "Epoch 10/100\n",
      "37800/37800 [==============================] - 2s 61us/step - loss: 0.1613 - acc: 0.9497 - val_loss: 0.1220 - val_acc: 0.9643\n",
      "Epoch 11/100\n",
      "37800/37800 [==============================] - 2s 61us/step - loss: 0.1570 - acc: 0.9523 - val_loss: 0.1257 - val_acc: 0.9638\n",
      "Epoch 12/100\n",
      "37800/37800 [==============================] - 2s 61us/step - loss: 0.1540 - acc: 0.9533 - val_loss: 0.1239 - val_acc: 0.9671\n",
      "Epoch 13/100\n",
      "37800/37800 [==============================] - 2s 61us/step - loss: 0.1425 - acc: 0.9563 - val_loss: 0.1243 - val_acc: 0.9643\n",
      "Epoch 14/100\n",
      "37800/37800 [==============================] - 2s 61us/step - loss: 0.1436 - acc: 0.9556 - val_loss: 0.1236 - val_acc: 0.9660\n",
      "Epoch 15/100\n",
      "37800/37800 [==============================] - 2s 62us/step - loss: 0.1377 - acc: 0.9580 - val_loss: 0.1230 - val_acc: 0.9674\n",
      "Epoch 16/100\n",
      "37800/37800 [==============================] - 2s 62us/step - loss: 0.1335 - acc: 0.9587 - val_loss: 0.1138 - val_acc: 0.9667\n",
      "Epoch 17/100\n",
      "37800/37800 [==============================] - 2s 61us/step - loss: 0.1319 - acc: 0.9586 - val_loss: 0.1183 - val_acc: 0.9710\n",
      "Epoch 18/100\n",
      "37800/37800 [==============================] - 2s 61us/step - loss: 0.1229 - acc: 0.9617 - val_loss: 0.1110 - val_acc: 0.9698\n",
      "Epoch 19/100\n",
      "37800/37800 [==============================] - 2s 62us/step - loss: 0.1243 - acc: 0.9612 - val_loss: 0.1207 - val_acc: 0.9662\n",
      "Epoch 20/100\n",
      "37800/37800 [==============================] - 2s 61us/step - loss: 0.1222 - acc: 0.9616 - val_loss: 0.1123 - val_acc: 0.9664\n",
      "Epoch 21/100\n",
      "37800/37800 [==============================] - 2s 62us/step - loss: 0.1230 - acc: 0.9625 - val_loss: 0.1215 - val_acc: 0.9667\n",
      "Epoch 22/100\n",
      "37800/37800 [==============================] - 2s 62us/step - loss: 0.1209 - acc: 0.9617 - val_loss: 0.1237 - val_acc: 0.9683\n",
      "Epoch 23/100\n",
      "37800/37800 [==============================] - 2s 62us/step - loss: 0.1188 - acc: 0.9624 - val_loss: 0.1268 - val_acc: 0.9679\n",
      "Epoch 24/100\n",
      "37800/37800 [==============================] - 2s 62us/step - loss: 0.1132 - acc: 0.9644 - val_loss: 0.1189 - val_acc: 0.9683\n",
      "Epoch 25/100\n",
      "37800/37800 [==============================] - 2s 61us/step - loss: 0.1126 - acc: 0.9634 - val_loss: 0.1204 - val_acc: 0.9690\n",
      "Epoch 26/100\n",
      "37800/37800 [==============================] - 2s 61us/step - loss: 0.1117 - acc: 0.9642 - val_loss: 0.1296 - val_acc: 0.9664\n",
      "Epoch 27/100\n",
      "37800/37800 [==============================] - 2s 61us/step - loss: 0.1092 - acc: 0.9659 - val_loss: 0.1266 - val_acc: 0.9664\n",
      "Epoch 28/100\n",
      "37800/37800 [==============================] - 2s 62us/step - loss: 0.1088 - acc: 0.9644 - val_loss: 0.1261 - val_acc: 0.9664\n",
      "Epoch 29/100\n",
      "37800/37800 [==============================] - 2s 63us/step - loss: 0.1055 - acc: 0.9656 - val_loss: 0.1268 - val_acc: 0.9664\n",
      "Epoch 30/100\n",
      "37800/37800 [==============================] - 2s 62us/step - loss: 0.1037 - acc: 0.9675 - val_loss: 0.1214 - val_acc: 0.9671\n",
      "Epoch 31/100\n",
      "37800/37800 [==============================] - 2s 62us/step - loss: 0.1052 - acc: 0.9677 - val_loss: 0.1210 - val_acc: 0.9676\n",
      "Epoch 32/100\n",
      "37800/37800 [==============================] - 2s 63us/step - loss: 0.0969 - acc: 0.9686 - val_loss: 0.1229 - val_acc: 0.9686\n",
      "Epoch 33/100\n",
      "37800/37800 [==============================] - 2s 62us/step - loss: 0.1029 - acc: 0.9671 - val_loss: 0.1268 - val_acc: 0.9679\n",
      "Epoch 34/100\n",
      "37800/37800 [==============================] - 2s 63us/step - loss: 0.1002 - acc: 0.9671 - val_loss: 0.1266 - val_acc: 0.9674\n",
      "Epoch 35/100\n",
      "37800/37800 [==============================] - 2s 61us/step - loss: 0.0988 - acc: 0.9683 - val_loss: 0.1304 - val_acc: 0.9638\n",
      "Epoch 36/100\n",
      "37800/37800 [==============================] - 2s 61us/step - loss: 0.0979 - acc: 0.9682 - val_loss: 0.1275 - val_acc: 0.9674\n",
      "Epoch 37/100\n",
      "37800/37800 [==============================] - 2s 62us/step - loss: 0.0974 - acc: 0.9698 - val_loss: 0.1284 - val_acc: 0.9664\n",
      "Epoch 38/100\n",
      "37800/37800 [==============================] - 2s 62us/step - loss: 0.0960 - acc: 0.9695 - val_loss: 0.1444 - val_acc: 0.9660\n",
      "Epoch 39/100\n",
      "37800/37800 [==============================] - 2s 62us/step - loss: 0.0970 - acc: 0.9682 - val_loss: 0.1280 - val_acc: 0.9657\n",
      "Epoch 40/100\n",
      "37800/37800 [==============================] - 2s 62us/step - loss: 0.0941 - acc: 0.9703 - val_loss: 0.1378 - val_acc: 0.9664\n",
      "Epoch 41/100\n",
      "37800/37800 [==============================] - 2s 62us/step - loss: 0.0945 - acc: 0.9705 - val_loss: 0.1210 - val_acc: 0.9690\n",
      "Epoch 42/100\n",
      "37800/37800 [==============================] - 2s 62us/step - loss: 0.0892 - acc: 0.9720 - val_loss: 0.1243 - val_acc: 0.9671\n",
      "Epoch 43/100\n",
      "37800/37800 [==============================] - 2s 61us/step - loss: 0.0892 - acc: 0.9715 - val_loss: 0.1272 - val_acc: 0.9693\n",
      "Epoch 44/100\n",
      "37800/37800 [==============================] - 2s 61us/step - loss: 0.0901 - acc: 0.9717 - val_loss: 0.1412 - val_acc: 0.9648\n",
      "Epoch 45/100\n",
      "37800/37800 [==============================] - 2s 61us/step - loss: 0.0923 - acc: 0.9702 - val_loss: 0.1306 - val_acc: 0.9683\n",
      "Epoch 46/100\n",
      "37800/37800 [==============================] - 2s 62us/step - loss: 0.0876 - acc: 0.9721 - val_loss: 0.1259 - val_acc: 0.9688\n",
      "Epoch 47/100\n",
      "37800/37800 [==============================] - 2s 61us/step - loss: 0.0879 - acc: 0.9715 - val_loss: 0.1321 - val_acc: 0.9679\n",
      "Epoch 48/100\n",
      "37800/37800 [==============================] - 2s 61us/step - loss: 0.0878 - acc: 0.9733 - val_loss: 0.1248 - val_acc: 0.9679\n",
      "Epoch 49/100\n",
      "37800/37800 [==============================] - 2s 61us/step - loss: 0.0843 - acc: 0.9727 - val_loss: 0.1344 - val_acc: 0.9710\n",
      "Epoch 50/100\n",
      "37800/37800 [==============================] - 2s 62us/step - loss: 0.0911 - acc: 0.9719 - val_loss: 0.1319 - val_acc: 0.9710\n",
      "Epoch 51/100\n",
      "37800/37800 [==============================] - 2s 62us/step - loss: 0.0897 - acc: 0.9716 - val_loss: 0.1389 - val_acc: 0.9702\n",
      "Epoch 52/100\n",
      "37800/37800 [==============================] - 2s 63us/step - loss: 0.0850 - acc: 0.9727 - val_loss: 0.1354 - val_acc: 0.9676\n",
      "Epoch 53/100\n",
      "37800/37800 [==============================] - 2s 63us/step - loss: 0.0845 - acc: 0.9740 - val_loss: 0.1334 - val_acc: 0.9690\n",
      "Epoch 54/100\n",
      "37800/37800 [==============================] - 2s 62us/step - loss: 0.0869 - acc: 0.9724 - val_loss: 0.1432 - val_acc: 0.9676\n",
      "Epoch 55/100\n",
      "37800/37800 [==============================] - 2s 62us/step - loss: 0.0845 - acc: 0.9736 - val_loss: 0.1352 - val_acc: 0.9686\n",
      "Epoch 56/100\n",
      "37800/37800 [==============================] - 2s 62us/step - loss: 0.0846 - acc: 0.9738 - val_loss: 0.1351 - val_acc: 0.9679\n",
      "Epoch 57/100\n",
      "37800/37800 [==============================] - 2s 61us/step - loss: 0.0785 - acc: 0.9748 - val_loss: 0.1356 - val_acc: 0.9681\n",
      "Epoch 58/100\n",
      "37800/37800 [==============================] - 2s 62us/step - loss: 0.0812 - acc: 0.9737 - val_loss: 0.1472 - val_acc: 0.9676\n",
      "Epoch 59/100\n",
      "37800/37800 [==============================] - 2s 62us/step - loss: 0.0852 - acc: 0.9726 - val_loss: 0.1385 - val_acc: 0.9674\n",
      "Epoch 60/100\n",
      "37800/37800 [==============================] - 2s 61us/step - loss: 0.0822 - acc: 0.9731 - val_loss: 0.1424 - val_acc: 0.9650\n",
      "Epoch 61/100\n",
      "37800/37800 [==============================] - 2s 61us/step - loss: 0.0813 - acc: 0.9745 - val_loss: 0.1376 - val_acc: 0.9667\n",
      "Epoch 62/100\n",
      "37800/37800 [==============================] - 2s 61us/step - loss: 0.0810 - acc: 0.9748 - val_loss: 0.1439 - val_acc: 0.9671\n",
      "Epoch 63/100\n",
      "37800/37800 [==============================] - 2s 61us/step - loss: 0.0797 - acc: 0.9743 - val_loss: 0.1487 - val_acc: 0.9652\n",
      "Epoch 64/100\n",
      "37800/37800 [==============================] - 2s 61us/step - loss: 0.0807 - acc: 0.9733 - val_loss: 0.1518 - val_acc: 0.9676\n",
      "Epoch 65/100\n",
      "37800/37800 [==============================] - 2s 61us/step - loss: 0.0799 - acc: 0.9742 - val_loss: 0.1560 - val_acc: 0.9674\n",
      "Epoch 66/100\n",
      "37800/37800 [==============================] - 2s 61us/step - loss: 0.0803 - acc: 0.9746 - val_loss: 0.1344 - val_acc: 0.9705\n",
      "Epoch 67/100\n",
      "37800/37800 [==============================] - 2s 61us/step - loss: 0.0784 - acc: 0.9756 - val_loss: 0.1445 - val_acc: 0.9667\n",
      "Epoch 68/100\n",
      "37800/37800 [==============================] - 2s 61us/step - loss: 0.0789 - acc: 0.9749 - val_loss: 0.1472 - val_acc: 0.9698\n",
      "Epoch 69/100\n",
      "37800/37800 [==============================] - 2s 61us/step - loss: 0.0777 - acc: 0.9754 - val_loss: 0.1514 - val_acc: 0.9660\n",
      "Epoch 70/100\n",
      "37800/37800 [==============================] - 2s 61us/step - loss: 0.0778 - acc: 0.9755 - val_loss: 0.1483 - val_acc: 0.9674\n",
      "Epoch 71/100\n",
      "37800/37800 [==============================] - 2s 62us/step - loss: 0.0759 - acc: 0.9761 - val_loss: 0.1432 - val_acc: 0.9688\n",
      "Epoch 72/100\n",
      "37800/37800 [==============================] - 2s 62us/step - loss: 0.0747 - acc: 0.9754 - val_loss: 0.1516 - val_acc: 0.9669\n",
      "Epoch 73/100\n",
      "37800/37800 [==============================] - 2s 62us/step - loss: 0.0741 - acc: 0.9755 - val_loss: 0.1448 - val_acc: 0.9690\n",
      "Epoch 74/100\n",
      "37800/37800 [==============================] - 2s 62us/step - loss: 0.0736 - acc: 0.9767 - val_loss: 0.1508 - val_acc: 0.9686\n",
      "Epoch 75/100\n",
      "37800/37800 [==============================] - 2s 61us/step - loss: 0.0704 - acc: 0.9762 - val_loss: 0.1557 - val_acc: 0.9652\n",
      "Epoch 76/100\n",
      "37800/37800 [==============================] - 2s 61us/step - loss: 0.0779 - acc: 0.9751 - val_loss: 0.1535 - val_acc: 0.9660\n",
      "Epoch 77/100\n",
      "37800/37800 [==============================] - 2s 61us/step - loss: 0.0756 - acc: 0.9752 - val_loss: 0.1454 - val_acc: 0.9662\n",
      "Epoch 78/100\n",
      "37800/37800 [==============================] - 2s 61us/step - loss: 0.0750 - acc: 0.9758 - val_loss: 0.1511 - val_acc: 0.9679\n",
      "Epoch 79/100\n",
      "37800/37800 [==============================] - 2s 62us/step - loss: 0.0752 - acc: 0.9753 - val_loss: 0.1554 - val_acc: 0.9669\n",
      "Epoch 80/100\n",
      "37800/37800 [==============================] - 2s 61us/step - loss: 0.0746 - acc: 0.9765 - val_loss: 0.1495 - val_acc: 0.9705\n",
      "Epoch 81/100\n",
      "37800/37800 [==============================] - 2s 61us/step - loss: 0.0737 - acc: 0.9766 - val_loss: 0.1473 - val_acc: 0.9695\n",
      "Epoch 82/100\n",
      "37800/37800 [==============================] - 2s 62us/step - loss: 0.0714 - acc: 0.9772 - val_loss: 0.1408 - val_acc: 0.9683\n",
      "Epoch 83/100\n",
      "37800/37800 [==============================] - 2s 61us/step - loss: 0.0721 - acc: 0.9769 - val_loss: 0.1570 - val_acc: 0.9676\n",
      "Epoch 84/100\n",
      "37800/37800 [==============================] - 2s 61us/step - loss: 0.0728 - acc: 0.9770 - val_loss: 0.1438 - val_acc: 0.9676\n",
      "Epoch 85/100\n",
      "37800/37800 [==============================] - 2s 62us/step - loss: 0.0702 - acc: 0.9776 - val_loss: 0.1596 - val_acc: 0.9688\n",
      "Epoch 86/100\n",
      "37800/37800 [==============================] - 2s 61us/step - loss: 0.0709 - acc: 0.9776 - val_loss: 0.1585 - val_acc: 0.9660\n",
      "Epoch 87/100\n",
      "37800/37800 [==============================] - 2s 61us/step - loss: 0.0753 - acc: 0.9767 - val_loss: 0.1484 - val_acc: 0.9671\n",
      "Epoch 88/100\n",
      "37800/37800 [==============================] - 2s 61us/step - loss: 0.0698 - acc: 0.9772 - val_loss: 0.1534 - val_acc: 0.9667\n",
      "Epoch 89/100\n",
      "37800/37800 [==============================] - 2s 61us/step - loss: 0.0677 - acc: 0.9790 - val_loss: 0.1475 - val_acc: 0.9674\n",
      "Epoch 90/100\n",
      "37800/37800 [==============================] - 2s 62us/step - loss: 0.0708 - acc: 0.9775 - val_loss: 0.1530 - val_acc: 0.9676\n",
      "Epoch 91/100\n",
      "37800/37800 [==============================] - 2s 61us/step - loss: 0.0716 - acc: 0.9762 - val_loss: 0.1685 - val_acc: 0.9676\n",
      "Epoch 92/100\n",
      "37800/37800 [==============================] - 2s 61us/step - loss: 0.0705 - acc: 0.9775 - val_loss: 0.1555 - val_acc: 0.9683\n",
      "Epoch 93/100\n",
      "37800/37800 [==============================] - 2s 60us/step - loss: 0.0708 - acc: 0.9772 - val_loss: 0.1581 - val_acc: 0.9688\n",
      "Epoch 94/100\n",
      "37800/37800 [==============================] - 2s 61us/step - loss: 0.0698 - acc: 0.9779 - val_loss: 0.1583 - val_acc: 0.9662\n",
      "Epoch 95/100\n",
      "37800/37800 [==============================] - 2s 61us/step - loss: 0.0680 - acc: 0.9780 - val_loss: 0.1572 - val_acc: 0.9679\n",
      "Epoch 96/100\n",
      "37800/37800 [==============================] - 2s 61us/step - loss: 0.0653 - acc: 0.9791 - val_loss: 0.1712 - val_acc: 0.9636\n",
      "Epoch 97/100\n",
      "37800/37800 [==============================] - 2s 61us/step - loss: 0.0741 - acc: 0.9761 - val_loss: 0.1578 - val_acc: 0.9667\n",
      "Epoch 98/100\n",
      "37800/37800 [==============================] - 2s 61us/step - loss: 0.0696 - acc: 0.9776 - val_loss: 0.1768 - val_acc: 0.9674\n",
      "Epoch 99/100\n",
      "37800/37800 [==============================] - 2s 61us/step - loss: 0.0687 - acc: 0.9785 - val_loss: 0.1633 - val_acc: 0.9650\n",
      "Epoch 100/100\n",
      "37800/37800 [==============================] - 2s 62us/step - loss: 0.0695 - acc: 0.9780 - val_loss: 0.1624 - val_acc: 0.9648\n"
     ]
    }
   ],
   "source": [
    "# Fit model on training data for network with dense input layer\n",
    "\n",
    "history = DigitNN.fit(X_train, y_train,\n",
    "          epochs=100,\n",
    "          verbose=1,\n",
    "          callbacks=[learning_rate_reduction, early_stops],\n",
    "          validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J_2GLi6avSeF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 851,
     "status": "ok",
     "timestamp": 1551833405005,
     "user": {
      "displayName": "Thomas Gibbons",
      "photoUrl": "https://lh6.googleusercontent.com/-aKNRGZRXBOQ/AAAAAAAAAAI/AAAAAAAAGk8/tKwL-Nlv8wU/s64/photo.jpg",
      "userId": "00153145788865022523"
     },
     "user_tz": 360
    },
    "id": "Y965DSk5vSeJ",
    "outputId": "f4448fc9-8c8d-4f4a-c14f-08e50199de7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running final scoring on test data\n",
      "4200/4200 [==============================] - 0s 26us/step\n",
      "The accuracy for this model is  0.97\n"
     ]
    }
   ],
   "source": [
    "# 10. Evaluate model on test data\n",
    "print (\"Running final scoring on test data\")\n",
    "score = DigitNN.evaluate(X_test, y_test, verbose=1)\n",
    "print (\"The accuracy for this model is \", format(score[1], \",.2f\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KJiV__LbvSeO"
   },
   "source": [
    "## Plot the Training History\n",
    "\n",
    "We store the performance during training is a variable named 'history'. The x-axis is the training time or number of epochs.\n",
    "\n",
    "- Accuracy: Accuracy of the predictions, hopefully this is increasing to near 1.0\n",
    "- Loss: How close the output is to the desired output, this should decrease to near 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 927,
     "status": "ok",
     "timestamp": 1551833406520,
     "user": {
      "displayName": "Thomas Gibbons",
      "photoUrl": "https://lh6.googleusercontent.com/-aKNRGZRXBOQ/AAAAAAAAAAI/AAAAAAAAGk8/tKwL-Nlv8wU/s64/photo.jpg",
      "userId": "00153145788865022523"
     },
     "user_tz": 360
    },
    "id": "EsT7FG9SvSeP",
    "outputId": "be87ca5d-edf6-4f15-8352-ba086a948d4b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAFZCAYAAACizedRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhjMREVGJ+X97+y22RYxx9wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x396 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss and accuracy curves for training and validation \n",
    "fig, ax = plt.subplots(2,1)\n",
    "\n",
    "ax[0].plot(history.history['acc'], color='b', label=\"Training accuracy\")\n",
    "ax[0].plot(history.history['val_acc'], color='r',label=\"Testing accuracy\")\n",
    "ax[0].set_title(\"Accruacy\")\n",
    "legend = ax[0].legend(loc='best', shadow=True)\n",
    "              \n",
    "ax[1].plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "ax[1].plot(history.history['val_loss'], color='r', label=\"Testing loss\",axes =ax[1])\n",
    "ax[1].set_title(\"Loss\")\n",
    "legend = ax[1].legend(loc='best', shadow=True)\n",
    "plt.ylim(0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xAHcXCEcfzIL"
   },
   "source": [
    "# Section 2: Create the Submission for Kaggle\n",
    "\n",
    "The following code generates a file named CIS3115_Submission.csv which you need to download to your local PC and then upload to [Kaggle's Digit Recognition competition](https://www.kaggle.com/c/digit-recognizer/submit).\n",
    "\n",
    "### Loading and Saving Weights\n",
    "\n",
    "As our networks get more complicated, it will take longer (often hours, if not days) to train them. At certain points you may want to save the weights for the network or load the wieghts. \n",
    "\n",
    "- This code can be used to save the weights of the current model to a file\n",
    "\n",
    "```\n",
    "DigitNN.save_weights('cis3115_model_save_1.hdf5')\n",
    "```\n",
    "\n",
    "- This code can be used to load the weights saved in a file\n",
    "\n",
    "```\n",
    "DigitNN.load_weights('cis3115_model_save_1.hdf5')\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YqcMfCNsjpOJ"
   },
   "outputs": [],
   "source": [
    "predictions = DigitNN.predict_classes(X_submit_kaggle, verbose=0)\n",
    "\n",
    "submissions=pd.DataFrame({\"ImageId\": list(range(1,len(predictions)+1)), \"Label\": predictions})\n",
    "\n",
    "submissions.to_csv(\"CIS3115_Submission.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d5UGK9BiWDW5"
   },
   "source": [
    "## Kaggle Submission\n",
    "\n",
    "Run the code above after training the network above. It will go through the 28,000 submission images and generate an prediction for each. These are saved in a file named \"CIS3115_Submission.csv\"\n",
    "\n",
    "**Colab Users: ** The submission file is stored in the Colab files tied to this colab notebook in the Google cloud. \n",
    "1. Open the left-side menu by clicking on the > icon near the top-left\n",
    "2. Select the file tab\n",
    "3. Hit the Refresh button and the file should be displayed in the list\n",
    "4. Right-click on the file and choose \"Download\" and save it to a folder on your PC.\n",
    "\n",
    "**Juptyter Notebook Users: ** The submission file will be stored in the same folder as your Jupyter notebook file.\n",
    "\n",
    "Once you have the file, return to  the [Kaggle Digit Recognition challenge](https://www.kaggle.com/c/digit-recognizer) and select the Submit button. Follow the steps to upload your submission and see how it scores.\n",
    "\n",
    "Record your initial submission score here: _ _ _ _ _ _ _ _ _ _ _ _\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cUg7_6I_ui3-"
   },
   "source": [
    "## Task 7: Report Best Score\n",
    "\n",
    "Try finding a good mix of the following:\n",
    "\n",
    "1. Number and size of hidden layers\n",
    "\n",
    "1. Number and rate of dropout layers\n",
    "\n",
    "1. Learning Rate reduction\n",
    "\n",
    "Submit your best network to the [Kaggle Digit Recognition challenge](https://www.kaggle.com/c/digit-recognizer) and compare it to your original score\n",
    "\n",
    "Original Kaggle scores here:  _ _ _ _ _ _ _ _ _ _\n",
    "Best Kaggle scores here:  _ _ _ _ _ _ _ _ _ _\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RUzZntKj1QFz"
   },
   "source": [
    "# Wrapping Up\n",
    "\n",
    "Remember to **share this sheet with your instructo**r and submit a link to it in Blackboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hNmZlPcKWv12"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "KmZ4LSJ7XLR9",
    "xAHcXCEcfzIL"
   ],
   "name": "Practice 8: Deep Learning in Neural Networks.ipynb",
   "provenance": [
    {
     "file_id": "1-i9hSMFj6CV6mLTNYXADQjlN2joTEdSK",
     "timestamp": 1551822387005
    },
    {
     "file_id": "1WZB0Zk2MxgPBnBZP0pqZQFzkrwuCbTtp",
     "timestamp": 1550948902012
    },
    {
     "file_id": "1DQL89Lgck-vLeOcQGbdLx7_ZRn0mg7IF",
     "timestamp": 1549765234813
    }
   ],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
