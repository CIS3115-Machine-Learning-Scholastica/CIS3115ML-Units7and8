{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Practice 7: Neural Networks.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "UcP0RHTjWP1q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Practice 7: Neural Networks\n",
        "\n",
        "Use this notebook as the starting point for the Practice activities.\n",
        "\n",
        "Student Name:    **[  Put your Name Here ]**\n",
        "\n",
        "**[Video Walkthough by Tom](https://www.youtube.com/watch?v=juginkyzZL0)**"
      ]
    },
    {
      "metadata": {
        "id": "KmZ4LSJ7XLR9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Section 0\n",
        "\n",
        "=== *You must run this section to set up things for any of the sections below * ===\n",
        "### Setting up Python tools\n",
        "\n",
        "\n",
        "\n",
        "We'll use three libraries for this tutorial: \n",
        "- [pandas](http://pandas.pydata.org/) : dataframes for spreadsheet-like data analysis, reading CSV files, time series\n",
        "- [numpy](http://www.numpy.org/) : for multidimensional data and linear algebra tools\n",
        "- [matplotlib](http://matplotlib.org/) : Simple plotting and graphing\n",
        "- [seaborn](http://stanford.edu/~mwaskom/software/seaborn/) : more advanced graphing\n",
        "-  [scikit-learn](https://scikit-learn.org/stable/) : provides many machine learning algorithms and tools to training and test.\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "RHAUKyWlWQ9L",
        "colab_type": "code",
        "outputId": "87ec1d59-7a8c-4496-d3e1-bfed3c2a7ad4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# First, we'll import pandas and numpy, two data processing libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# We'll also import seaborn and matplot, twp Python graphing libraries\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "# Import the needed sklearn libraries\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# The Keras library provides support for neural networks and deep learning\n",
        "print (\"====== This should generate a FutureWaring on Conversion ===== ignore this warning\")\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Lambda, Flatten, LSTM\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "from keras.utils import np_utils\n",
        "\n",
        "# We will turn off some warns in this notebook to make it easier to read for new students\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "====== This should generate a FutureWaring on Conversion ===== ignore this warning\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Vz1Qt8p_U4g2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## The data sets\n",
        "We will work with the following data sets:\n",
        "- Section I: Iris flower dataset from Practice 2 & 4\n",
        "- Section II: Breast cancer data from Project 1 & 2\n",
        "- Section III: [MNIST](https://en.wikipedia.org/wiki/MNIST_database) handwritten digits. This is our first image data set. Each image is 16x16 grayscale pixels. \n",
        "<p>\n"
      ]
    },
    {
      "metadata": {
        "id": "qllYJsYUU5mT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Section I: Iris Flowers \n",
        "=== *You must run Section 0 before this section* ===\n",
        "## Neural Networks to Classify Iris Flowers\n",
        "\n",
        "Remember the iris flower data set has four features for each flower. Each flower is in one of three species of Iris.\n",
        "\n",
        "We will train a simple neural network to learn to classify the Iris flowers\n",
        "\n",
        "First we will read in the Iris database...\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "Zw-0pDmtWRAN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Read in the iris data file from stored in a raw file in GitHub\n",
        "url_iris = 'https://raw.githubusercontent.com/CIS3115-Machine-Learning-Scholastica/CIS3115ML-Units3and4/master/Iris.csv'\n",
        "iris = pd.read_csv(url_iris)\n",
        "# Set the Id column as the index since it is unique for each flower\n",
        "iris.set_index('Id', inplace=True)\n",
        "\n",
        "species = iris['Species'].unique()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1OtgWe9yWRDZ",
        "colab_type": "code",
        "outputId": "5635baae-50f5-4a74-b2eb-34f24dc56749",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        }
      },
      "cell_type": "code",
      "source": [
        "# Display the first 5 flowers to make sure the data was read in\n",
        "iris.head(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SepalLengthCm</th>\n",
              "      <th>SepalWidthCm</th>\n",
              "      <th>PetalLengthCm</th>\n",
              "      <th>PetalWidthCm</th>\n",
              "      <th>Species</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
              "Id                                                                       \n",
              "1             5.1           3.5            1.4           0.2  Iris-setosa\n",
              "2             4.9           3.0            1.4           0.2  Iris-setosa\n",
              "3             4.7           3.2            1.3           0.2  Iris-setosa\n",
              "4             4.6           3.1            1.5           0.2  Iris-setosa\n",
              "5             5.0           3.6            1.4           0.2  Iris-setosa"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "metadata": {
        "id": "estP1rJqjiqL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Set up the input and output \n",
        "In the past we have called the input **\"X\"** and the output **\"y\"** but when working with multiple datasets we will use **\"Xiris\"** for the input features for the iris flower dataset. Likewise we will use **\"yiris\"** for the output categories for the iris flowers.\n",
        "\n",
        "\n",
        "**Scale Data:** Neural Networks work best with the inputs are between -1 and +1, so the MinMaxScaler is used to scale all the inputs to the range 0 to +1.\n",
        "\n",
        "\n",
        "**Split the Data:** The Iris data is split with 80% used for training and 20% used for testing.\n",
        "\n",
        "**One-Hot Encoding:** Neural Networks like the output as one-hot encoding. This is a list of values, one for each category, which are all zeros except one which is 1 which represents the correct category.\n",
        "\n",
        "So, if we have three iris species, we map each one to a one-hot encoding:\n",
        "- Iris-setosa = [ 1, 0, 0 ]\n",
        "- Iris-virginica  = [ 0, 1, 0 ]\n",
        "- Iris-versicolor = [ 0, 0, 1 ]\n"
      ]
    },
    {
      "metadata": {
        "id": "OqLNbqIzch1o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_Size = 4\n",
        "output_Size = 3\n",
        "\n",
        "feature_columns = ['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm','PetalWidthCm']\n",
        "Xiris = iris[feature_columns].values\n",
        "# We need the species labels converted to numbers for the neural network\n",
        "yiris = LabelEncoder().fit_transform(iris[\"Species\"])\n",
        "\n",
        "# Scale the input data\n",
        "mmScaler = MinMaxScaler()\n",
        "Xiris = mmScaler.fit_transform(Xiris)\n",
        "\n",
        "# Split the data into 80% for training and 20% for testing out the models\n",
        "X_train, X_test, y_train, y_test = train_test_split(Xiris, yiris.ravel(), test_size=0.2)\n",
        "\n",
        "# Format the output as one-hot encodings. Each output has three values with only one with a value of 1\n",
        "y_train = np_utils.to_categorical(y_train, output_Size)\n",
        "y_test = np_utils.to_categorical(y_test, output_Size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B5Hy611A_4ys",
        "colab_type": "code",
        "outputId": "922498d4-2754-4d21-957e-ed9546fb4fe0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "cell_type": "code",
      "source": [
        "print (\"X_train training data is 120 flowers with 4 features each: \" ,X_train.shape)\n",
        "print (\"X_test testing data is 30 flowers with 4 features each: \" ,X_test.shape)\n",
        "\n",
        "print (\"y_train output is 1 of 3 species for 120 flowers: \" ,y_train.shape)\n",
        "print (\"y_test output is 1 of 3 species for 30 flowers: : \" ,y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train training data is 120 flowers with 4 features each:  (120, 4)\n",
            "X_test testing data is 30 flowers with 4 features each:  (30, 4)\n",
            "y_train output is 1 of 3 species for 120 flowers:  (120, 3)\n",
            "y_test output is 1 of 3 species for 30 flowers: :  (30, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hL9TP4GBkqfs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Neural Network\n",
        "\n",
        "The following code sets up a sequential, four layer neural network. Sequential means that each layer is connected to the layer listed before it:\n",
        "- Input layer: Input values are assigned to these units\n",
        "- Hidden layer 1: 8 units using Rectified Linear Units (relu)\n",
        "- Hidden layer 2: 6 units using Rectified Linear Units (relu)\n",
        "- Output  layer: 3 units using softmax so sum of the three units will be 1.0\n",
        "\n",
        "![neural network diagram](https://raw.githubusercontent.com/CIS3115-Machine-Learning-Scholastica/CIS3115ML-Units7and8/master/Iris%20Neural%20Network.png)\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "PLf6EIn1Zot0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Task 1: Understanding the Network Stucture\n",
        "\n",
        "Answer the following questions about the network:\n",
        "\n",
        "1. Why is the input size or dimension set to 4? Is this dependent on the data? Why is it 4 with the iris data?\n",
        "2. Why is the the output size set to 3? How is dependent on the data used? How does this relate to the iris data?\n",
        "3. This network uses \"Dense\" hidden layers where each node is connected to every node in the previous layer. Node 3 in Hidden layer 1 is highlight in the diagram. Which nodes from which layer does Node 3 recieve inputs from?\n",
        "4. Node 3 in Hidden layer 1 is highlight in the diagram. Which nodes from which layer does Node 3 send its outputs to?"
      ]
    },
    {
      "metadata": {
        "id": "_dDDMlkIPtnD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Set up the Neural Network\n",
        "\n",
        "input_Size = 4\n",
        "output_Size = 3\n",
        "\n",
        "Iris_neuralNetwork = Sequential()\n",
        "Iris_neuralNetwork.add(Dense(20, activation='relu', input_dim=(input_Size)))\n",
        "Iris_neuralNetwork.add(Dense(10, activation='relu'))\n",
        "Iris_neuralNetwork.add(Dense(output_Size, activation='softmax'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W38NgcRmQ1Bz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Compile Neural Network\n",
        "\n",
        "This builds the Neural network. You must specify \n",
        "- optimizer = 'adam' is a common gradient decent method for changing the wieghts during training\n",
        "- loss =  'categorical_crossentropy' is used when you have a number of distinct categories and items can only be in one category.\n",
        "- metrics = 'accuracy' will output the accuracy of the classification, the percent of time the network gets the classification correct"
      ]
    },
    {
      "metadata": {
        "id": "cb5e3PZA01kv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Compile neural network model\n",
        "Iris_neuralNetwork.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SIp1LLRAUlwe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train the Neural Network\n",
        "\n",
        "This will run all 120 training flowers through the network and update the weights. The 30 testing flowers are then used to validate the model. \n",
        "\n",
        "- epochs = 50 means to run the training 50 times. \n",
        "- Performance measues:\n",
        " - loss: is a measurement of how far the outputs are from the desired outputs. This should get smaller over time.\n",
        " - acc: is the prediction accuracy as a percent so 0.67 means the model predicts the correct flower 67% of the time. \n",
        " - val_loss: the loss calculated using the testing flowers rather than the training flowers.\n",
        " - val_acc: the accuracy calculated using the testing flowers rather than the training flowers.\n",
        " \n",
        " \n",
        "Note: sometimes training will take minutes, if not hours to run, especially later when we get to complex networks"
      ]
    },
    {
      "metadata": {
        "id": "Y4Pu8MRq01oa",
        "colab_type": "code",
        "outputId": "3b1e562a-0e37-47e3-a7a9-49a057cba4a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 7146
        }
      },
      "cell_type": "code",
      "source": [
        "# Fit model on training data for network with dense input layer\n",
        "history = Iris_neuralNetwork.fit(X_train, y_train,\n",
        "          epochs=200,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 120 samples, validate on 30 samples\n",
            "Epoch 1/200\n",
            "120/120 [==============================] - 1s 6ms/step - loss: 1.0950 - acc: 0.3333 - val_loss: 1.0959 - val_acc: 0.3333\n",
            "Epoch 2/200\n",
            "120/120 [==============================] - 0s 91us/step - loss: 1.0890 - acc: 0.3333 - val_loss: 1.0910 - val_acc: 0.3333\n",
            "Epoch 3/200\n",
            "120/120 [==============================] - 0s 104us/step - loss: 1.0835 - acc: 0.3333 - val_loss: 1.0869 - val_acc: 0.3333\n",
            "Epoch 4/200\n",
            "120/120 [==============================] - 0s 74us/step - loss: 1.0789 - acc: 0.3333 - val_loss: 1.0833 - val_acc: 0.3333\n",
            "Epoch 5/200\n",
            "120/120 [==============================] - 0s 74us/step - loss: 1.0741 - acc: 0.3333 - val_loss: 1.0791 - val_acc: 0.3333\n",
            "Epoch 6/200\n",
            "120/120 [==============================] - 0s 72us/step - loss: 1.0692 - acc: 0.3333 - val_loss: 1.0744 - val_acc: 0.3333\n",
            "Epoch 7/200\n",
            "120/120 [==============================] - 0s 72us/step - loss: 1.0641 - acc: 0.3333 - val_loss: 1.0690 - val_acc: 0.3333\n",
            "Epoch 8/200\n",
            "120/120 [==============================] - 0s 88us/step - loss: 1.0587 - acc: 0.3333 - val_loss: 1.0634 - val_acc: 0.3333\n",
            "Epoch 9/200\n",
            "120/120 [==============================] - 0s 83us/step - loss: 1.0535 - acc: 0.3333 - val_loss: 1.0575 - val_acc: 0.3333\n",
            "Epoch 10/200\n",
            "120/120 [==============================] - 0s 87us/step - loss: 1.0475 - acc: 0.3333 - val_loss: 1.0517 - val_acc: 0.3333\n",
            "Epoch 11/200\n",
            "120/120 [==============================] - 0s 94us/step - loss: 1.0412 - acc: 0.3333 - val_loss: 1.0458 - val_acc: 0.3333\n",
            "Epoch 12/200\n",
            "120/120 [==============================] - 0s 76us/step - loss: 1.0356 - acc: 0.3417 - val_loss: 1.0403 - val_acc: 0.4333\n",
            "Epoch 13/200\n",
            "120/120 [==============================] - 0s 84us/step - loss: 1.0303 - acc: 0.3917 - val_loss: 1.0348 - val_acc: 0.4667\n",
            "Epoch 14/200\n",
            "120/120 [==============================] - 0s 85us/step - loss: 1.0244 - acc: 0.4167 - val_loss: 1.0290 - val_acc: 0.5000\n",
            "Epoch 15/200\n",
            "120/120 [==============================] - 0s 83us/step - loss: 1.0186 - acc: 0.4750 - val_loss: 1.0235 - val_acc: 0.5333\n",
            "Epoch 16/200\n",
            "120/120 [==============================] - 0s 84us/step - loss: 1.0124 - acc: 0.5500 - val_loss: 1.0175 - val_acc: 0.6000\n",
            "Epoch 17/200\n",
            "120/120 [==============================] - 0s 113us/step - loss: 1.0063 - acc: 0.6000 - val_loss: 1.0115 - val_acc: 0.6667\n",
            "Epoch 18/200\n",
            "120/120 [==============================] - 0s 103us/step - loss: 1.0000 - acc: 0.6167 - val_loss: 1.0053 - val_acc: 0.7667\n",
            "Epoch 19/200\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.9936 - acc: 0.6750 - val_loss: 0.9990 - val_acc: 0.8000\n",
            "Epoch 20/200\n",
            "120/120 [==============================] - 0s 74us/step - loss: 0.9871 - acc: 0.7333 - val_loss: 0.9921 - val_acc: 0.8000\n",
            "Epoch 21/200\n",
            "120/120 [==============================] - 0s 69us/step - loss: 0.9806 - acc: 0.7500 - val_loss: 0.9850 - val_acc: 0.8667\n",
            "Epoch 22/200\n",
            "120/120 [==============================] - 0s 74us/step - loss: 0.9743 - acc: 0.7583 - val_loss: 0.9782 - val_acc: 0.9333\n",
            "Epoch 23/200\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.9669 - acc: 0.7583 - val_loss: 0.9711 - val_acc: 0.9333\n",
            "Epoch 24/200\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.9599 - acc: 0.7833 - val_loss: 0.9636 - val_acc: 0.9333\n",
            "Epoch 25/200\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.9526 - acc: 0.8417 - val_loss: 0.9558 - val_acc: 0.9333\n",
            "Epoch 26/200\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.9450 - acc: 0.8417 - val_loss: 0.9476 - val_acc: 0.8667\n",
            "Epoch 27/200\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.9370 - acc: 0.8250 - val_loss: 0.9389 - val_acc: 0.8667\n",
            "Epoch 28/200\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.9288 - acc: 0.8250 - val_loss: 0.9301 - val_acc: 0.8667\n",
            "Epoch 29/200\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.9208 - acc: 0.8250 - val_loss: 0.9210 - val_acc: 0.8667\n",
            "Epoch 30/200\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.9117 - acc: 0.8000 - val_loss: 0.9119 - val_acc: 0.8333\n",
            "Epoch 31/200\n",
            "120/120 [==============================] - 0s 118us/step - loss: 0.9026 - acc: 0.7833 - val_loss: 0.9023 - val_acc: 0.7667\n",
            "Epoch 32/200\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.8930 - acc: 0.7750 - val_loss: 0.8923 - val_acc: 0.7667\n",
            "Epoch 33/200\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.8837 - acc: 0.7500 - val_loss: 0.8823 - val_acc: 0.7333\n",
            "Epoch 34/200\n",
            "120/120 [==============================] - 0s 110us/step - loss: 0.8733 - acc: 0.7417 - val_loss: 0.8715 - val_acc: 0.7333\n",
            "Epoch 35/200\n",
            "120/120 [==============================] - 0s 143us/step - loss: 0.8630 - acc: 0.7333 - val_loss: 0.8602 - val_acc: 0.7333\n",
            "Epoch 36/200\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.8521 - acc: 0.7167 - val_loss: 0.8488 - val_acc: 0.7000\n",
            "Epoch 37/200\n",
            "120/120 [==============================] - 0s 110us/step - loss: 0.8414 - acc: 0.6833 - val_loss: 0.8367 - val_acc: 0.7000\n",
            "Epoch 38/200\n",
            "120/120 [==============================] - 0s 109us/step - loss: 0.8299 - acc: 0.6833 - val_loss: 0.8237 - val_acc: 0.7000\n",
            "Epoch 39/200\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.8178 - acc: 0.6833 - val_loss: 0.8095 - val_acc: 0.7000\n",
            "Epoch 40/200\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.8042 - acc: 0.6833 - val_loss: 0.7935 - val_acc: 0.7000\n",
            "Epoch 41/200\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.7893 - acc: 0.6833 - val_loss: 0.7760 - val_acc: 0.7000\n",
            "Epoch 42/200\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.7741 - acc: 0.6750 - val_loss: 0.7582 - val_acc: 0.7000\n",
            "Epoch 43/200\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.7574 - acc: 0.6750 - val_loss: 0.7402 - val_acc: 0.7000\n",
            "Epoch 44/200\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.7412 - acc: 0.6750 - val_loss: 0.7224 - val_acc: 0.7000\n",
            "Epoch 45/200\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.7250 - acc: 0.6750 - val_loss: 0.7052 - val_acc: 0.7000\n",
            "Epoch 46/200\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.7103 - acc: 0.6667 - val_loss: 0.6886 - val_acc: 0.6667\n",
            "Epoch 47/200\n",
            "120/120 [==============================] - 0s 124us/step - loss: 0.6944 - acc: 0.6667 - val_loss: 0.6730 - val_acc: 0.6667\n",
            "Epoch 48/200\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.6804 - acc: 0.6667 - val_loss: 0.6576 - val_acc: 0.6667\n",
            "Epoch 49/200\n",
            "120/120 [==============================] - 0s 74us/step - loss: 0.6654 - acc: 0.6667 - val_loss: 0.6424 - val_acc: 0.6667\n",
            "Epoch 50/200\n",
            "120/120 [==============================] - 0s 113us/step - loss: 0.6520 - acc: 0.6667 - val_loss: 0.6276 - val_acc: 0.6667\n",
            "Epoch 51/200\n",
            "120/120 [==============================] - 0s 77us/step - loss: 0.6386 - acc: 0.6667 - val_loss: 0.6130 - val_acc: 0.6667\n",
            "Epoch 52/200\n",
            "120/120 [==============================] - 0s 114us/step - loss: 0.6260 - acc: 0.6833 - val_loss: 0.5984 - val_acc: 0.6667\n",
            "Epoch 53/200\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.6129 - acc: 0.6833 - val_loss: 0.5850 - val_acc: 0.6667\n",
            "Epoch 54/200\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.6011 - acc: 0.6917 - val_loss: 0.5719 - val_acc: 0.6667\n",
            "Epoch 55/200\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.5894 - acc: 0.7000 - val_loss: 0.5595 - val_acc: 0.6667\n",
            "Epoch 56/200\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.5786 - acc: 0.7000 - val_loss: 0.5478 - val_acc: 0.6667\n",
            "Epoch 57/200\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.5683 - acc: 0.7000 - val_loss: 0.5363 - val_acc: 0.6667\n",
            "Epoch 58/200\n",
            "120/120 [==============================] - 0s 113us/step - loss: 0.5577 - acc: 0.7000 - val_loss: 0.5255 - val_acc: 0.6667\n",
            "Epoch 59/200\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.5484 - acc: 0.7083 - val_loss: 0.5151 - val_acc: 0.7000\n",
            "Epoch 60/200\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.5391 - acc: 0.7083 - val_loss: 0.5048 - val_acc: 0.7000\n",
            "Epoch 61/200\n",
            "120/120 [==============================] - 0s 86us/step - loss: 0.5306 - acc: 0.7500 - val_loss: 0.4951 - val_acc: 0.7333\n",
            "Epoch 62/200\n",
            "120/120 [==============================] - 0s 77us/step - loss: 0.5221 - acc: 0.7500 - val_loss: 0.4861 - val_acc: 0.7333\n",
            "Epoch 63/200\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.5146 - acc: 0.7667 - val_loss: 0.4774 - val_acc: 0.7667\n",
            "Epoch 64/200\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.5068 - acc: 0.7917 - val_loss: 0.4696 - val_acc: 0.7667\n",
            "Epoch 65/200\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.4995 - acc: 0.7917 - val_loss: 0.4622 - val_acc: 0.8000\n",
            "Epoch 66/200\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.4934 - acc: 0.7833 - val_loss: 0.4560 - val_acc: 0.7667\n",
            "Epoch 67/200\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.4861 - acc: 0.7833 - val_loss: 0.4489 - val_acc: 0.7667\n",
            "Epoch 68/200\n",
            "120/120 [==============================] - 0s 114us/step - loss: 0.4798 - acc: 0.7833 - val_loss: 0.4422 - val_acc: 0.8333\n",
            "Epoch 69/200\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.4739 - acc: 0.7917 - val_loss: 0.4360 - val_acc: 0.8667\n",
            "Epoch 70/200\n",
            "120/120 [==============================] - 0s 109us/step - loss: 0.4679 - acc: 0.8000 - val_loss: 0.4300 - val_acc: 0.8667\n",
            "Epoch 71/200\n",
            "120/120 [==============================] - 0s 119us/step - loss: 0.4626 - acc: 0.8250 - val_loss: 0.4238 - val_acc: 0.8667\n",
            "Epoch 72/200\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.4570 - acc: 0.8333 - val_loss: 0.4184 - val_acc: 0.9000\n",
            "Epoch 73/200\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.4520 - acc: 0.8417 - val_loss: 0.4129 - val_acc: 0.9000\n",
            "Epoch 74/200\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.4467 - acc: 0.8583 - val_loss: 0.4081 - val_acc: 0.9000\n",
            "Epoch 75/200\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.4417 - acc: 0.8667 - val_loss: 0.4037 - val_acc: 0.9000\n",
            "Epoch 76/200\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.4371 - acc: 0.8500 - val_loss: 0.3992 - val_acc: 0.9000\n",
            "Epoch 77/200\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.4325 - acc: 0.8583 - val_loss: 0.3946 - val_acc: 0.9000\n",
            "Epoch 78/200\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.4279 - acc: 0.8667 - val_loss: 0.3904 - val_acc: 0.9000\n",
            "Epoch 79/200\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.4236 - acc: 0.8667 - val_loss: 0.3862 - val_acc: 0.9000\n",
            "Epoch 80/200\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.4198 - acc: 0.8583 - val_loss: 0.3825 - val_acc: 0.9000\n",
            "Epoch 81/200\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.4149 - acc: 0.8750 - val_loss: 0.3775 - val_acc: 0.9333\n",
            "Epoch 82/200\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.4107 - acc: 0.9000 - val_loss: 0.3725 - val_acc: 0.9333\n",
            "Epoch 83/200\n",
            "120/120 [==============================] - 0s 109us/step - loss: 0.4074 - acc: 0.9333 - val_loss: 0.3675 - val_acc: 0.9333\n",
            "Epoch 84/200\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.4028 - acc: 0.9500 - val_loss: 0.3637 - val_acc: 0.9333\n",
            "Epoch 85/200\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.3987 - acc: 0.9417 - val_loss: 0.3600 - val_acc: 0.9333\n",
            "Epoch 86/200\n",
            "120/120 [==============================] - 0s 80us/step - loss: 0.3946 - acc: 0.9417 - val_loss: 0.3568 - val_acc: 0.9333\n",
            "Epoch 87/200\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.3906 - acc: 0.9333 - val_loss: 0.3534 - val_acc: 0.9333\n",
            "Epoch 88/200\n",
            "120/120 [==============================] - 0s 107us/step - loss: 0.3871 - acc: 0.9333 - val_loss: 0.3496 - val_acc: 0.9667\n",
            "Epoch 89/200\n",
            "120/120 [==============================] - 0s 113us/step - loss: 0.3831 - acc: 0.9333 - val_loss: 0.3469 - val_acc: 0.9333\n",
            "Epoch 90/200\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.3794 - acc: 0.9333 - val_loss: 0.3440 - val_acc: 0.9333\n",
            "Epoch 91/200\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.3756 - acc: 0.9333 - val_loss: 0.3398 - val_acc: 0.9333\n",
            "Epoch 92/200\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.3717 - acc: 0.9333 - val_loss: 0.3357 - val_acc: 0.9667\n",
            "Epoch 93/200\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.3681 - acc: 0.9500 - val_loss: 0.3313 - val_acc: 0.9667\n",
            "Epoch 94/200\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.3655 - acc: 0.9500 - val_loss: 0.3270 - val_acc: 0.9667\n",
            "Epoch 95/200\n",
            "120/120 [==============================] - 0s 75us/step - loss: 0.3607 - acc: 0.9500 - val_loss: 0.3243 - val_acc: 0.9667\n",
            "Epoch 96/200\n",
            "120/120 [==============================] - 0s 102us/step - loss: 0.3567 - acc: 0.9500 - val_loss: 0.3215 - val_acc: 0.9667\n",
            "Epoch 97/200\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.3534 - acc: 0.9500 - val_loss: 0.3189 - val_acc: 0.9667\n",
            "Epoch 98/200\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.3502 - acc: 0.9500 - val_loss: 0.3149 - val_acc: 0.9667\n",
            "Epoch 99/200\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.3463 - acc: 0.9583 - val_loss: 0.3113 - val_acc: 0.9667\n",
            "Epoch 100/200\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.3425 - acc: 0.9583 - val_loss: 0.3081 - val_acc: 0.9667\n",
            "Epoch 101/200\n",
            "120/120 [==============================] - 0s 78us/step - loss: 0.3390 - acc: 0.9583 - val_loss: 0.3043 - val_acc: 0.9667\n",
            "Epoch 102/200\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.3357 - acc: 0.9667 - val_loss: 0.3005 - val_acc: 0.9667\n",
            "Epoch 103/200\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.3319 - acc: 0.9667 - val_loss: 0.2982 - val_acc: 0.9667\n",
            "Epoch 104/200\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.3282 - acc: 0.9667 - val_loss: 0.2950 - val_acc: 0.9667\n",
            "Epoch 105/200\n",
            "120/120 [==============================] - 0s 110us/step - loss: 0.3247 - acc: 0.9667 - val_loss: 0.2919 - val_acc: 0.9667\n",
            "Epoch 106/200\n",
            "120/120 [==============================] - 0s 110us/step - loss: 0.3211 - acc: 0.9667 - val_loss: 0.2891 - val_acc: 0.9667\n",
            "Epoch 107/200\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.3178 - acc: 0.9667 - val_loss: 0.2857 - val_acc: 0.9667\n",
            "Epoch 108/200\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.3142 - acc: 0.9667 - val_loss: 0.2823 - val_acc: 0.9667\n",
            "Epoch 109/200\n",
            "120/120 [==============================] - 0s 68us/step - loss: 0.3108 - acc: 0.9667 - val_loss: 0.2783 - val_acc: 0.9667\n",
            "Epoch 110/200\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.3073 - acc: 0.9667 - val_loss: 0.2751 - val_acc: 0.9667\n",
            "Epoch 111/200\n",
            "120/120 [==============================] - 0s 77us/step - loss: 0.3046 - acc: 0.9667 - val_loss: 0.2733 - val_acc: 0.9667\n",
            "Epoch 112/200\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.3004 - acc: 0.9667 - val_loss: 0.2693 - val_acc: 0.9667\n",
            "Epoch 113/200\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2968 - acc: 0.9667 - val_loss: 0.2659 - val_acc: 0.9667\n",
            "Epoch 114/200\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.2941 - acc: 0.9667 - val_loss: 0.2632 - val_acc: 0.9667\n",
            "Epoch 115/200\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.2902 - acc: 0.9667 - val_loss: 0.2596 - val_acc: 0.9667\n",
            "Epoch 116/200\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.2868 - acc: 0.9667 - val_loss: 0.2566 - val_acc: 0.9667\n",
            "Epoch 117/200\n",
            "120/120 [==============================] - 0s 108us/step - loss: 0.2840 - acc: 0.9667 - val_loss: 0.2536 - val_acc: 0.9667\n",
            "Epoch 118/200\n",
            "120/120 [==============================] - 0s 95us/step - loss: 0.2803 - acc: 0.9667 - val_loss: 0.2518 - val_acc: 0.9667\n",
            "Epoch 119/200\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2772 - acc: 0.9667 - val_loss: 0.2495 - val_acc: 0.9667\n",
            "Epoch 120/200\n",
            "120/120 [==============================] - 0s 104us/step - loss: 0.2738 - acc: 0.9667 - val_loss: 0.2467 - val_acc: 0.9667\n",
            "Epoch 121/200\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2708 - acc: 0.9667 - val_loss: 0.2427 - val_acc: 0.9667\n",
            "Epoch 122/200\n",
            "120/120 [==============================] - 0s 79us/step - loss: 0.2679 - acc: 0.9667 - val_loss: 0.2403 - val_acc: 0.9667\n",
            "Epoch 123/200\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.2644 - acc: 0.9667 - val_loss: 0.2365 - val_acc: 0.9667\n",
            "Epoch 124/200\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2615 - acc: 0.9750 - val_loss: 0.2333 - val_acc: 0.9667\n",
            "Epoch 125/200\n",
            "120/120 [==============================] - 0s 79us/step - loss: 0.2584 - acc: 0.9750 - val_loss: 0.2308 - val_acc: 0.9667\n",
            "Epoch 126/200\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.2552 - acc: 0.9750 - val_loss: 0.2287 - val_acc: 0.9667\n",
            "Epoch 127/200\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.2528 - acc: 0.9667 - val_loss: 0.2281 - val_acc: 0.9667\n",
            "Epoch 128/200\n",
            "120/120 [==============================] - 0s 82us/step - loss: 0.2495 - acc: 0.9667 - val_loss: 0.2257 - val_acc: 0.9667\n",
            "Epoch 129/200\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.2465 - acc: 0.9667 - val_loss: 0.2218 - val_acc: 0.9667\n",
            "Epoch 130/200\n",
            "120/120 [==============================] - 0s 74us/step - loss: 0.2434 - acc: 0.9750 - val_loss: 0.2185 - val_acc: 0.9667\n",
            "Epoch 131/200\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.2406 - acc: 0.9750 - val_loss: 0.2152 - val_acc: 0.9667\n",
            "Epoch 132/200\n",
            "120/120 [==============================] - 0s 119us/step - loss: 0.2377 - acc: 0.9667 - val_loss: 0.2130 - val_acc: 0.9667\n",
            "Epoch 133/200\n",
            "120/120 [==============================] - 0s 79us/step - loss: 0.2357 - acc: 0.9667 - val_loss: 0.2115 - val_acc: 0.9667\n",
            "Epoch 134/200\n",
            "120/120 [==============================] - 0s 65us/step - loss: 0.2321 - acc: 0.9750 - val_loss: 0.2090 - val_acc: 0.9667\n",
            "Epoch 135/200\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.2296 - acc: 0.9750 - val_loss: 0.2073 - val_acc: 0.9667\n",
            "Epoch 136/200\n",
            "120/120 [==============================] - 0s 100us/step - loss: 0.2269 - acc: 0.9750 - val_loss: 0.2045 - val_acc: 0.9667\n",
            "Epoch 137/200\n",
            "120/120 [==============================] - 0s 126us/step - loss: 0.2243 - acc: 0.9750 - val_loss: 0.2025 - val_acc: 0.9667\n",
            "Epoch 138/200\n",
            "120/120 [==============================] - 0s 137us/step - loss: 0.2215 - acc: 0.9750 - val_loss: 0.1993 - val_acc: 0.9667\n",
            "Epoch 139/200\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.2194 - acc: 0.9667 - val_loss: 0.1954 - val_acc: 0.9667\n",
            "Epoch 140/200\n",
            "120/120 [==============================] - 0s 90us/step - loss: 0.2165 - acc: 0.9667 - val_loss: 0.1934 - val_acc: 0.9667\n",
            "Epoch 141/200\n",
            "120/120 [==============================] - 0s 67us/step - loss: 0.2146 - acc: 0.9667 - val_loss: 0.1926 - val_acc: 0.9667\n",
            "Epoch 142/200\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.2112 - acc: 0.9667 - val_loss: 0.1905 - val_acc: 0.9667\n",
            "Epoch 143/200\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.2091 - acc: 0.9667 - val_loss: 0.1881 - val_acc: 0.9667\n",
            "Epoch 144/200\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.2065 - acc: 0.9667 - val_loss: 0.1864 - val_acc: 0.9667\n",
            "Epoch 145/200\n",
            "120/120 [==============================] - 0s 98us/step - loss: 0.2040 - acc: 0.9667 - val_loss: 0.1844 - val_acc: 0.9667\n",
            "Epoch 146/200\n",
            "120/120 [==============================] - 0s 105us/step - loss: 0.2017 - acc: 0.9667 - val_loss: 0.1824 - val_acc: 0.9667\n",
            "Epoch 147/200\n",
            "120/120 [==============================] - 0s 106us/step - loss: 0.1998 - acc: 0.9667 - val_loss: 0.1805 - val_acc: 0.9667\n",
            "Epoch 148/200\n",
            "120/120 [==============================] - 0s 103us/step - loss: 0.1982 - acc: 0.9667 - val_loss: 0.1770 - val_acc: 0.9667\n",
            "Epoch 149/200\n",
            "120/120 [==============================] - 0s 79us/step - loss: 0.1949 - acc: 0.9667 - val_loss: 0.1756 - val_acc: 0.9667\n",
            "Epoch 150/200\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.1928 - acc: 0.9667 - val_loss: 0.1740 - val_acc: 0.9667\n",
            "Epoch 151/200\n",
            "120/120 [==============================] - 0s 80us/step - loss: 0.1907 - acc: 0.9667 - val_loss: 0.1722 - val_acc: 0.9667\n",
            "Epoch 152/200\n",
            "120/120 [==============================] - 0s 83us/step - loss: 0.1885 - acc: 0.9667 - val_loss: 0.1707 - val_acc: 0.9667\n",
            "Epoch 153/200\n",
            "120/120 [==============================] - 0s 91us/step - loss: 0.1866 - acc: 0.9667 - val_loss: 0.1692 - val_acc: 0.9667\n",
            "Epoch 154/200\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.1848 - acc: 0.9667 - val_loss: 0.1658 - val_acc: 0.9667\n",
            "Epoch 155/200\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.1823 - acc: 0.9667 - val_loss: 0.1634 - val_acc: 0.9667\n",
            "Epoch 156/200\n",
            "120/120 [==============================] - 0s 96us/step - loss: 0.1801 - acc: 0.9667 - val_loss: 0.1615 - val_acc: 0.9667\n",
            "Epoch 157/200\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.1776 - acc: 0.9667 - val_loss: 0.1584 - val_acc: 0.9667\n",
            "Epoch 158/200\n",
            "120/120 [==============================] - 0s 114us/step - loss: 0.1746 - acc: 0.9667 - val_loss: 0.1566 - val_acc: 0.9667\n",
            "Epoch 159/200\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.1725 - acc: 0.9667 - val_loss: 0.1549 - val_acc: 0.9667\n",
            "Epoch 160/200\n",
            "120/120 [==============================] - 0s 97us/step - loss: 0.1701 - acc: 0.9667 - val_loss: 0.1533 - val_acc: 0.9667\n",
            "Epoch 161/200\n",
            "120/120 [==============================] - 0s 93us/step - loss: 0.1692 - acc: 0.9667 - val_loss: 0.1526 - val_acc: 0.9667\n",
            "Epoch 162/200\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.1661 - acc: 0.9667 - val_loss: 0.1494 - val_acc: 0.9667\n",
            "Epoch 163/200\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.1636 - acc: 0.9667 - val_loss: 0.1466 - val_acc: 0.9667\n",
            "Epoch 164/200\n",
            "120/120 [==============================] - 0s 139us/step - loss: 0.1619 - acc: 0.9667 - val_loss: 0.1445 - val_acc: 0.9667\n",
            "Epoch 165/200\n",
            "120/120 [==============================] - 0s 94us/step - loss: 0.1606 - acc: 0.9667 - val_loss: 0.1429 - val_acc: 0.9667\n",
            "Epoch 166/200\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.1587 - acc: 0.9750 - val_loss: 0.1407 - val_acc: 0.9667\n",
            "Epoch 167/200\n",
            "120/120 [==============================] - 0s 148us/step - loss: 0.1572 - acc: 0.9750 - val_loss: 0.1390 - val_acc: 0.9667\n",
            "Epoch 168/200\n",
            "120/120 [==============================] - 0s 144us/step - loss: 0.1549 - acc: 0.9667 - val_loss: 0.1389 - val_acc: 0.9667\n",
            "Epoch 169/200\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.1533 - acc: 0.9667 - val_loss: 0.1391 - val_acc: 0.9667\n",
            "Epoch 170/200\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.1513 - acc: 0.9667 - val_loss: 0.1371 - val_acc: 0.9667\n",
            "Epoch 171/200\n",
            "120/120 [==============================] - 0s 77us/step - loss: 0.1497 - acc: 0.9667 - val_loss: 0.1349 - val_acc: 0.9667\n",
            "Epoch 172/200\n",
            "120/120 [==============================] - 0s 63us/step - loss: 0.1478 - acc: 0.9667 - val_loss: 0.1333 - val_acc: 0.9667\n",
            "Epoch 173/200\n",
            "120/120 [==============================] - 0s 72us/step - loss: 0.1463 - acc: 0.9667 - val_loss: 0.1319 - val_acc: 0.9667\n",
            "Epoch 174/200\n",
            "120/120 [==============================] - 0s 79us/step - loss: 0.1449 - acc: 0.9667 - val_loss: 0.1301 - val_acc: 0.9667\n",
            "Epoch 175/200\n",
            "120/120 [==============================] - 0s 73us/step - loss: 0.1433 - acc: 0.9667 - val_loss: 0.1291 - val_acc: 0.9667\n",
            "Epoch 176/200\n",
            "120/120 [==============================] - 0s 68us/step - loss: 0.1418 - acc: 0.9667 - val_loss: 0.1278 - val_acc: 0.9667\n",
            "Epoch 177/200\n",
            "120/120 [==============================] - 0s 71us/step - loss: 0.1404 - acc: 0.9667 - val_loss: 0.1276 - val_acc: 0.9667\n",
            "Epoch 178/200\n",
            "120/120 [==============================] - 0s 71us/step - loss: 0.1389 - acc: 0.9667 - val_loss: 0.1265 - val_acc: 0.9667\n",
            "Epoch 179/200\n",
            "120/120 [==============================] - 0s 69us/step - loss: 0.1377 - acc: 0.9667 - val_loss: 0.1246 - val_acc: 0.9667\n",
            "Epoch 180/200\n",
            "120/120 [==============================] - 0s 87us/step - loss: 0.1361 - acc: 0.9667 - val_loss: 0.1236 - val_acc: 0.9667\n",
            "Epoch 181/200\n",
            "120/120 [==============================] - 0s 75us/step - loss: 0.1346 - acc: 0.9667 - val_loss: 0.1224 - val_acc: 0.9667\n",
            "Epoch 182/200\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.1335 - acc: 0.9667 - val_loss: 0.1213 - val_acc: 0.9667\n",
            "Epoch 183/200\n",
            "120/120 [==============================] - 0s 92us/step - loss: 0.1324 - acc: 0.9667 - val_loss: 0.1199 - val_acc: 0.9667\n",
            "Epoch 184/200\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.1309 - acc: 0.9667 - val_loss: 0.1189 - val_acc: 0.9667\n",
            "Epoch 185/200\n",
            "120/120 [==============================] - 0s 76us/step - loss: 0.1295 - acc: 0.9667 - val_loss: 0.1180 - val_acc: 0.9667\n",
            "Epoch 186/200\n",
            "120/120 [==============================] - 0s 88us/step - loss: 0.1295 - acc: 0.9667 - val_loss: 0.1164 - val_acc: 0.9667\n",
            "Epoch 187/200\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.1273 - acc: 0.9667 - val_loss: 0.1161 - val_acc: 0.9667\n",
            "Epoch 188/200\n",
            "120/120 [==============================] - 0s 68us/step - loss: 0.1264 - acc: 0.9667 - val_loss: 0.1150 - val_acc: 0.9667\n",
            "Epoch 189/200\n",
            "120/120 [==============================] - 0s 101us/step - loss: 0.1248 - acc: 0.9667 - val_loss: 0.1147 - val_acc: 0.9667\n",
            "Epoch 190/200\n",
            "120/120 [==============================] - 0s 72us/step - loss: 0.1242 - acc: 0.9667 - val_loss: 0.1141 - val_acc: 0.9667\n",
            "Epoch 191/200\n",
            "120/120 [==============================] - 0s 75us/step - loss: 0.1231 - acc: 0.9667 - val_loss: 0.1132 - val_acc: 0.9667\n",
            "Epoch 192/200\n",
            "120/120 [==============================] - 0s 79us/step - loss: 0.1220 - acc: 0.9667 - val_loss: 0.1113 - val_acc: 0.9667\n",
            "Epoch 193/200\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.1208 - acc: 0.9667 - val_loss: 0.1103 - val_acc: 0.9667\n",
            "Epoch 194/200\n",
            "120/120 [==============================] - 0s 85us/step - loss: 0.1197 - acc: 0.9667 - val_loss: 0.1092 - val_acc: 0.9667\n",
            "Epoch 195/200\n",
            "120/120 [==============================] - 0s 84us/step - loss: 0.1188 - acc: 0.9667 - val_loss: 0.1082 - val_acc: 0.9667\n",
            "Epoch 196/200\n",
            "120/120 [==============================] - 0s 81us/step - loss: 0.1182 - acc: 0.9667 - val_loss: 0.1075 - val_acc: 0.9667\n",
            "Epoch 197/200\n",
            "120/120 [==============================] - 0s 79us/step - loss: 0.1177 - acc: 0.9667 - val_loss: 0.1080 - val_acc: 0.9667\n",
            "Epoch 198/200\n",
            "120/120 [==============================] - 0s 99us/step - loss: 0.1161 - acc: 0.9667 - val_loss: 0.1069 - val_acc: 0.9667\n",
            "Epoch 199/200\n",
            "120/120 [==============================] - 0s 77us/step - loss: 0.1154 - acc: 0.9667 - val_loss: 0.1055 - val_acc: 0.9667\n",
            "Epoch 200/200\n",
            "120/120 [==============================] - 0s 89us/step - loss: 0.1140 - acc: 0.9667 - val_loss: 0.1047 - val_acc: 0.9667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "B65n9trA1qzU",
        "colab_type": "code",
        "outputId": "b75fb6ac-7d4b-4311-c4c5-1a2840ae9bdd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "cell_type": "code",
      "source": [
        "# Evaluate model on test data\n",
        "print (\"Running final scoring on test data\")\n",
        "score = Iris_neuralNetwork.evaluate(X_test, y_test, verbose=1)\n",
        "print (\"The accuracy for this model is \", format(score[1], \",.2f\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running final scoring on test data\n",
            "\r30/30 [==============================] - 0s 36us/step\n",
            "The accuracy for this model is  0.97\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NRH1j7fWXjo9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Plot the Training History\n",
        "\n",
        "We store the performance during training is a variable named 'history'. The x-axis is the training time or number of epochs.\n",
        "\n",
        "- Accuracy: Accuracy of the predictions, hopefully this is increasing to near 1.0\n",
        "- Loss: How close the output is to the desired output, this should decrease to near 0.0"
      ]
    },
    {
      "metadata": {
        "id": "vYYUtTbmYMgw",
        "colab_type": "code",
        "outputId": "db4d93d9-03be-466a-d9c1-4f4280e63a65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        }
      },
      "cell_type": "code",
      "source": [
        "# Plot the loss and accuracy curves for training and validation \n",
        "fig, ax = plt.subplots(2,1)\n",
        "\n",
        "ax[0].plot(history.history['acc'], color='b', label=\"Training accuracy\")\n",
        "ax[0].plot(history.history['val_acc'], color='r',label=\"Testing accuracy\")\n",
        "ax[0].set_title(\"Accruacy\")\n",
        "legend = ax[0].legend(loc='best', shadow=True)\n",
        "ax[0].set_ylim([0, 1])\n",
        "              \n",
        "ax[1].plot(history.history['loss'], color='b', label=\"Training loss\")\n",
        "ax[1].plot(history.history['val_loss'], color='r', label=\"Testing loss\",axes =ax[1])\n",
        "ax[1].set_title(\"Loss\")\n",
        "legend = ax[1].legend(loc='best', shadow=True)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFZCAYAAACv05cWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 576x396 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "ZI-vfLqjeIsG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Task 2: Improving the Network\n",
        "\n",
        "1. What is the training accuracy, acc, and the testing accuracy, val_acc, of the model?\n",
        "\n",
        "2. Change the number of epochs used during training from 50 to 200. \n",
        " - Go back up to Task 1 and re-run all the cells down to this cell to re-train the network\n",
        " \n",
        "3. Try more hidden layers. The more hidden layers, the  more internal features the nework can learn. Try changing the number of nodes in each hidden layer to larger numbers. How accurate can you get the network? \n",
        " - Go back up to Task 1 and re-run all the cells down to this cell to re-train the network"
      ]
    },
    {
      "metadata": {
        "id": "XTszMKsRmO5L",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Task 3: Prediction\n",
        "Once we have trained or fit the model to the data, we can use it to make predictions.\n",
        "\n",
        "Here we will predict the iris species for a new flower with \n",
        "- SepalLengthCm = 5.2\t\n",
        "- SepalWidthCm = 3.3\n",
        "- PetalLengthCm = 1.4\n",
        "- PetalWidthCm\t= 0.2\n",
        "\n",
        "This should be a Iris-setosa\n",
        "\n",
        "Change the code below to make a prediction for a new flower with the following measurements.\n",
        "- SepalLengthCm = 4.2\t\n",
        "- SepalWidthCm = 3.0\n",
        "- PetalLengthCm = 3.4\n",
        "- PetalWidthCm\t= 1.2\n",
        "\n",
        "This should be a Iris-setosa"
      ]
    },
    {
      "metadata": {
        "id": "oRfDA6gj-HyV",
        "colab_type": "code",
        "outputId": "973c83d7-02b3-4f72-c132-7fe98195206c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "# The parameter order is SepalLengthCm, SepalWidthCm, PetalLengthCm, PetalWidthCm\n",
        "flowerMeasurements = [ [5.2, 3.3, 1.4, 0.2] ]\n",
        "\n",
        "# Scale the data since the original training data was scaled\n",
        "flowerMeasurements = mmScaler.transform(flowerMeasurements).reshape(1, -1) \n",
        "\n",
        "# Use the neural network to generate the prediction\n",
        "prediction = Iris_neuralNetwork.predict(flowerMeasurements)\n",
        "\n",
        "# The prediction is a score for how likely each species is, the highest value corresponds to the predicted species\n",
        "print (\"Predicted score for each Iris species is \", prediction)\n",
        "# [ 0.994  0.005  0.00002]\n",
        "\n",
        "# select the indix with the maximum probability\n",
        "irisNum = np.argmax(prediction)\n",
        "print (\"This flower is of type : \", species[irisNum])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted score for each Iris species is  [[9.9437934e-01 5.6180633e-03 2.5489630e-06]]\n",
            "This flower is of type :  Iris-setosa\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "k7SCGnzo_bzK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Section II: Breast Cancer Data\n",
        "=== *You must run Section 0 before this section* ===\n",
        "### Neural Networks with the cancer dataset\n",
        "The following code loads in the breast cancer dataset"
      ]
    },
    {
      "metadata": {
        "id": "5l2xF4cdVxuZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        " \n",
        "  # Read in the breast cancer data file from stored in a raw file in GitHub\n",
        "url_bc = 'https://raw.githubusercontent.com/CIS3115-Machine-Learning-Scholastica/CIS3115ML-Units3and4/master/breast-cancer-wisconsin-data.csv'\n",
        "\n",
        "cancer = pd.read_csv(url_bc)\n",
        "# Set the Id column as the index since it is unique for each pati\n",
        "cancer.set_index('id', inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gmhyyINeV_YW",
        "colab_type": "code",
        "outputId": "fda659a6-4c60-4734-a504-5d88bde0245d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "cell_type": "code",
      "source": [
        "# Display the first 5 rows at the start, or head, of the dataframe\n",
        "cancer.head(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>...</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <th>Unnamed: 32</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>842302</th>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>...</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>842517</th>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>...</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84300903</th>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>...</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84348301</th>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>...</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84358402</th>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>...</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows  32 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
              "id                                                                         \n",
              "842302           M        17.99         10.38          122.80     1001.0   \n",
              "842517           M        20.57         17.77          132.90     1326.0   \n",
              "84300903         M        19.69         21.25          130.00     1203.0   \n",
              "84348301         M        11.42         20.38           77.58      386.1   \n",
              "84358402         M        20.29         14.34          135.10     1297.0   \n",
              "\n",
              "          smoothness_mean  compactness_mean  concavity_mean  \\\n",
              "id                                                            \n",
              "842302            0.11840           0.27760          0.3001   \n",
              "842517            0.08474           0.07864          0.0869   \n",
              "84300903          0.10960           0.15990          0.1974   \n",
              "84348301          0.14250           0.28390          0.2414   \n",
              "84358402          0.10030           0.13280          0.1980   \n",
              "\n",
              "          concave points_mean  symmetry_mean     ...       texture_worst  \\\n",
              "id                                               ...                       \n",
              "842302                0.14710         0.2419     ...               17.33   \n",
              "842517                0.07017         0.1812     ...               23.41   \n",
              "84300903              0.12790         0.2069     ...               25.53   \n",
              "84348301              0.10520         0.2597     ...               26.50   \n",
              "84358402              0.10430         0.1809     ...               16.67   \n",
              "\n",
              "          perimeter_worst  area_worst  smoothness_worst  compactness_worst  \\\n",
              "id                                                                           \n",
              "842302             184.60      2019.0            0.1622             0.6656   \n",
              "842517             158.80      1956.0            0.1238             0.1866   \n",
              "84300903           152.50      1709.0            0.1444             0.4245   \n",
              "84348301            98.87       567.7            0.2098             0.8663   \n",
              "84358402           152.20      1575.0            0.1374             0.2050   \n",
              "\n",
              "          concavity_worst  concave points_worst  symmetry_worst  \\\n",
              "id                                                                \n",
              "842302             0.7119                0.2654          0.4601   \n",
              "842517             0.2416                0.1860          0.2750   \n",
              "84300903           0.4504                0.2430          0.3613   \n",
              "84348301           0.6869                0.2575          0.6638   \n",
              "84358402           0.4000                0.1625          0.2364   \n",
              "\n",
              "          fractal_dimension_worst  Unnamed: 32  \n",
              "id                                              \n",
              "842302                    0.11890          NaN  \n",
              "842517                    0.08902          NaN  \n",
              "84300903                  0.08758          NaN  \n",
              "84348301                  0.17300          NaN  \n",
              "84358402                  0.07678          NaN  \n",
              "\n",
              "[5 rows x 32 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "metadata": {
        "id": "hYMuTD6qxjIV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Set up the Input and output, X and y\n",
        "\n",
        "Here we will use Xcancer and ycancer instead of X and y for the input features and output categories.\n",
        "\n",
        "This data set has 569 tumors with 30 features on each tumor, along with each tumor's category as Benign or Malignant.\n",
        "\n",
        "**Scale Data:** Neural Networks work best with the inputs are between -1 and +1, so the MinMaxScaler is used to scale all the inputs to the range 0 to +1.\n",
        "\n",
        "**Split the Data:** The Iris data is split with 80% used for training and 20% used for testing.\n",
        "\n",
        "**One-Hot Encoding:** Neural Networks like the output as one-hot encoding. This is a list of values, one for each category, which are all zeros except one which is 1 which represents the correct category.\n",
        "\n",
        "So, if we have two outputs, benign or malignant, we map each one to a one-hot encoding:\n",
        "- Benign = [ 0, 1 ]\n",
        "- Malignant  = [ 1, 0 ]\n"
      ]
    },
    {
      "metadata": {
        "id": "8mwusXDNbdYr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_Size = 30\n",
        "output_Size = 2\n",
        "\n",
        "# === Select all the data for input ===\n",
        "Xcancer = cancer.iloc[:, 1:31] \n",
        "# The output is the diagnosis where M is Malignant and B is Benign\n",
        "# We need the diagnosis labels converted to numbers for the neural network\n",
        "ycancer = LabelEncoder().fit_transform(cancer[\"diagnosis\"])\n",
        "\n",
        "# Scale the input data\n",
        "mmScaler = MinMaxScaler()\n",
        "Xcancer = mmScaler.fit_transform(Xcancer)\n",
        "\n",
        "# Split the data into 80% for training and 20% for testing out the models\n",
        "X_train, X_test, y_train, y_test = train_test_split(Xcancer, ycancer.ravel(), test_size=0.2)\n",
        "\n",
        "# Format the output as one-hot encodings. Each output has two values with only one with a value of 1\n",
        "y_train = np_utils.to_categorical(y_train, output_Size)\n",
        "y_test = np_utils.to_categorical(y_test, output_Size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Gy4v9h5gpcA4",
        "colab_type": "code",
        "outputId": "45220416-3c7a-40db-fe6c-ef5cac8fe35c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "cell_type": "code",
      "source": [
        "print (\"X_train training data is 455 tumors with 30 features each: \" ,X_train.shape)\n",
        "print (\"X_test testing data is 114 tumors with 30 features each: \" ,X_test.shape)\n",
        "\n",
        "print (\"y_train output is 1 of 2 diagnosis for 455 tumors: \" ,y_train.shape)\n",
        "print (\"y_test output is 1 of 2 diagnosis for 114 tumors: : \" ,y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train training data is 455 tumors with 30 features each:  (455, 30)\n",
            "X_test testing data is 114 tumors with 30 features each:  (114, 30)\n",
            "y_train output is 1 of 2 diagnosis for 455 tumors:  (455, 2)\n",
            "y_test output is 1 of 2 diagnosis for 114 tumors: :  (114, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "wwEfdxzUFS-p"
      },
      "cell_type": "markdown",
      "source": [
        "## Neural Network\n",
        "\n",
        "The following code sets up a sequential, four layer neural network. Sequential means that each layer is connected to the layer listed before it:\n",
        "- Input layer: 30 tumor features used as input values\n",
        "- Hidden layer 1: 10 units using Rectified Linear Units (relu)\n",
        "- Hidden layer 2: 5 units using Rectified Linear Units (relu)\n",
        "- Output  layer: 2 units using softmax to predict if tumor is benign or malignant\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "bezF0_uGa4SU"
      },
      "cell_type": "markdown",
      "source": [
        "### Neural Network\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "phwGAAm8a4Sg",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Set up the Neural Network\n",
        "\n",
        "input_Size = 30\n",
        "output_Size = 2\n",
        "\n",
        "Cancer_neuralNetwork = Sequential()\n",
        "Cancer_neuralNetwork.add(Dense(10, activation='relu', input_dim=(input_Size)))\n",
        "Cancer_neuralNetwork.add(Dense(5, activation='relu'))\n",
        "Cancer_neuralNetwork.add(Dense(output_Size, activation='softmax'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OpLnPdtCpQp5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Compile Neural Network\n",
        "\n",
        "This builds the Neural network. You must specify \n",
        "- optimizer = 'adam' is a common gradient decent method for changing the wieghts during training\n",
        "- loss =  'categorical_crossentropy' is used when you have a number of distinct categories and items can only be in one category.\n",
        "- metrics = 'accuracy' will output the accuracy of the classification, the percent of time the network gets the classification correct"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "8nr6ANMha4S1",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Compile neural network model\n",
        "Cancer_neuralNetwork.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZbvLBTe6pUZn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train the Neural Network\n",
        "\n",
        "This will run all 120 training flowers through the network and update the weights. The 30 testing flowers are then used to validate the model. \n",
        "\n",
        "- epochs = 50 means to run the training 50 times. \n",
        "- Performance measues:\n",
        " - loss: is a measurement of how far the outputs are from the desired outputs. This should get smaller over time.\n",
        " - acc: is the prediction accuracy as a percent so 0.67 means the model predicts the correct flower 67% of the time. \n",
        " - val_loss: the loss calculated using the testing flowers rather than the training flowers.\n",
        " - val_acc: the accuracy calculated using the testing flowers rather than the training flowers.\n",
        " \n",
        " \n",
        "Note: sometimes training will take minutes, if not hours to run, especially later when we get to complex networks"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "b5ba857b-aabc-4602-8bef-f845f1db2c37",
        "id": "0p7yooe4a4TS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1812
        }
      },
      "cell_type": "code",
      "source": [
        "# Fit model on training data for network with dense input layer\n",
        "batch_size = 100\n",
        "epochs = 50\n",
        "history = Cancer_neuralNetwork.fit(X_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=2,\n",
        "          validation_data=(X_test, y_test))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 455 samples, validate on 114 samples\n",
            "Epoch 1/50\n",
            " - 1s - loss: 0.6896 - acc: 0.3846 - val_loss: 0.6905 - val_acc: 0.3333\n",
            "Epoch 2/50\n",
            " - 0s - loss: 0.6851 - acc: 0.4044 - val_loss: 0.6852 - val_acc: 0.4386\n",
            "Epoch 3/50\n",
            " - 0s - loss: 0.6808 - acc: 0.5209 - val_loss: 0.6796 - val_acc: 0.6140\n",
            "Epoch 4/50\n",
            " - 0s - loss: 0.6763 - acc: 0.7429 - val_loss: 0.6740 - val_acc: 0.8684\n",
            "Epoch 5/50\n",
            " - 0s - loss: 0.6716 - acc: 0.8659 - val_loss: 0.6682 - val_acc: 0.8947\n",
            "Epoch 6/50\n",
            " - 0s - loss: 0.6667 - acc: 0.9099 - val_loss: 0.6622 - val_acc: 0.8947\n",
            "Epoch 7/50\n",
            " - 0s - loss: 0.6615 - acc: 0.9011 - val_loss: 0.6557 - val_acc: 0.8860\n",
            "Epoch 8/50\n",
            " - 0s - loss: 0.6560 - acc: 0.9011 - val_loss: 0.6488 - val_acc: 0.9035\n",
            "Epoch 9/50\n",
            " - 0s - loss: 0.6501 - acc: 0.8945 - val_loss: 0.6414 - val_acc: 0.9123\n",
            "Epoch 10/50\n",
            " - 0s - loss: 0.6437 - acc: 0.8835 - val_loss: 0.6337 - val_acc: 0.9123\n",
            "Epoch 11/50\n",
            " - 0s - loss: 0.6370 - acc: 0.8769 - val_loss: 0.6248 - val_acc: 0.9123\n",
            "Epoch 12/50\n",
            " - 0s - loss: 0.6293 - acc: 0.8549 - val_loss: 0.6148 - val_acc: 0.9123\n",
            "Epoch 13/50\n",
            " - 0s - loss: 0.6204 - acc: 0.8396 - val_loss: 0.6031 - val_acc: 0.8947\n",
            "Epoch 14/50\n",
            " - 0s - loss: 0.6101 - acc: 0.8330 - val_loss: 0.5891 - val_acc: 0.8860\n",
            "Epoch 15/50\n",
            " - 0s - loss: 0.5978 - acc: 0.8198 - val_loss: 0.5724 - val_acc: 0.8509\n",
            "Epoch 16/50\n",
            " - 0s - loss: 0.5841 - acc: 0.7934 - val_loss: 0.5553 - val_acc: 0.8421\n",
            "Epoch 17/50\n",
            " - 0s - loss: 0.5698 - acc: 0.7934 - val_loss: 0.5397 - val_acc: 0.8509\n",
            "Epoch 18/50\n",
            " - 0s - loss: 0.5568 - acc: 0.8000 - val_loss: 0.5254 - val_acc: 0.8509\n",
            "Epoch 19/50\n",
            " - 0s - loss: 0.5441 - acc: 0.8198 - val_loss: 0.5112 - val_acc: 0.8860\n",
            "Epoch 20/50\n",
            " - 0s - loss: 0.5316 - acc: 0.8374 - val_loss: 0.4980 - val_acc: 0.9035\n",
            "Epoch 21/50\n",
            " - 0s - loss: 0.5184 - acc: 0.8527 - val_loss: 0.4853 - val_acc: 0.9035\n",
            "Epoch 22/50\n",
            " - 0s - loss: 0.5053 - acc: 0.8725 - val_loss: 0.4719 - val_acc: 0.9123\n",
            "Epoch 23/50\n",
            " - 0s - loss: 0.4924 - acc: 0.8813 - val_loss: 0.4579 - val_acc: 0.9123\n",
            "Epoch 24/50\n",
            " - 0s - loss: 0.4796 - acc: 0.8879 - val_loss: 0.4440 - val_acc: 0.9123\n",
            "Epoch 25/50\n",
            " - 0s - loss: 0.4667 - acc: 0.8923 - val_loss: 0.4303 - val_acc: 0.9123\n",
            "Epoch 26/50\n",
            " - 0s - loss: 0.4539 - acc: 0.8945 - val_loss: 0.4162 - val_acc: 0.9123\n",
            "Epoch 27/50\n",
            " - 0s - loss: 0.4412 - acc: 0.8923 - val_loss: 0.4028 - val_acc: 0.9123\n",
            "Epoch 28/50\n",
            " - 0s - loss: 0.4293 - acc: 0.8923 - val_loss: 0.3899 - val_acc: 0.9123\n",
            "Epoch 29/50\n",
            " - 0s - loss: 0.4175 - acc: 0.8945 - val_loss: 0.3786 - val_acc: 0.9211\n",
            "Epoch 30/50\n",
            " - 0s - loss: 0.4055 - acc: 0.8967 - val_loss: 0.3671 - val_acc: 0.9211\n",
            "Epoch 31/50\n",
            " - 0s - loss: 0.3943 - acc: 0.8989 - val_loss: 0.3552 - val_acc: 0.9211\n",
            "Epoch 32/50\n",
            " - 0s - loss: 0.3836 - acc: 0.8989 - val_loss: 0.3443 - val_acc: 0.9386\n",
            "Epoch 33/50\n",
            " - 0s - loss: 0.3727 - acc: 0.9055 - val_loss: 0.3354 - val_acc: 0.9298\n",
            "Epoch 34/50\n",
            " - 0s - loss: 0.3628 - acc: 0.9143 - val_loss: 0.3259 - val_acc: 0.9298\n",
            "Epoch 35/50\n",
            " - 0s - loss: 0.3528 - acc: 0.9143 - val_loss: 0.3164 - val_acc: 0.9298\n",
            "Epoch 36/50\n",
            " - 0s - loss: 0.3435 - acc: 0.9165 - val_loss: 0.3060 - val_acc: 0.9298\n",
            "Epoch 37/50\n",
            " - 0s - loss: 0.3345 - acc: 0.9165 - val_loss: 0.2960 - val_acc: 0.9298\n",
            "Epoch 38/50\n",
            " - 0s - loss: 0.3259 - acc: 0.9165 - val_loss: 0.2878 - val_acc: 0.9298\n",
            "Epoch 39/50\n",
            " - 0s - loss: 0.3174 - acc: 0.9187 - val_loss: 0.2805 - val_acc: 0.9298\n",
            "Epoch 40/50\n",
            " - 0s - loss: 0.3097 - acc: 0.9121 - val_loss: 0.2744 - val_acc: 0.9386\n",
            "Epoch 41/50\n",
            " - 0s - loss: 0.3022 - acc: 0.9209 - val_loss: 0.2671 - val_acc: 0.9386\n",
            "Epoch 42/50\n",
            " - 0s - loss: 0.2952 - acc: 0.9209 - val_loss: 0.2594 - val_acc: 0.9386\n",
            "Epoch 43/50\n",
            " - 0s - loss: 0.2882 - acc: 0.9209 - val_loss: 0.2537 - val_acc: 0.9386\n",
            "Epoch 44/50\n",
            " - 0s - loss: 0.2818 - acc: 0.9209 - val_loss: 0.2472 - val_acc: 0.9386\n",
            "Epoch 45/50\n",
            " - 0s - loss: 0.2757 - acc: 0.9187 - val_loss: 0.2417 - val_acc: 0.9386\n",
            "Epoch 46/50\n",
            " - 0s - loss: 0.2698 - acc: 0.9187 - val_loss: 0.2361 - val_acc: 0.9386\n",
            "Epoch 47/50\n",
            " - 0s - loss: 0.2644 - acc: 0.9165 - val_loss: 0.2322 - val_acc: 0.9386\n",
            "Epoch 48/50\n",
            " - 0s - loss: 0.2590 - acc: 0.9209 - val_loss: 0.2269 - val_acc: 0.9386\n",
            "Epoch 49/50\n",
            " - 0s - loss: 0.2539 - acc: 0.9187 - val_loss: 0.2220 - val_acc: 0.9386\n",
            "Epoch 50/50\n",
            " - 0s - loss: 0.2489 - acc: 0.9209 - val_loss: 0.2176 - val_acc: 0.9386\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Hrt-q_47L6jo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Task 4: Increasing the Accuracy of Cancer Predictions\n",
        "\n",
        "In Project 2 you tried a number of different classification methods with the breast cancer data. Here are some typical results from Project 2:\n",
        "\n",
        "- K-Nearest Neighbors (KNN): 95%\n",
        "- Support Vector Machine (SVM): 97%\n",
        "- Decision Trees (DT): 93%\n",
        "\n",
        "Question 1: How accurate is the original network with hidden layers of 10 & 5 units trained for 50 epohs?\n",
        "\n",
        "Question 2: How high of an accuracy can you get by adding more hidden units and training for more epochs? What configuration gave you the best results?\n",
        "\n",
        "Question 3: Do neural networks seem comparable in this task with KNN, SVM and DT?"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "4462afb7-e355-4cb4-b7e9-0e73dede3680",
        "id": "wgeLikQfa4Te",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "cell_type": "code",
      "source": [
        "# Evaluate model on test data\n",
        "print (\"Running final scoring on test data\")\n",
        "score = Cancer_neuralNetwork.evaluate(X_test, y_test, verbose=1)\n",
        "print (\"The accuracy for this model is \", format(score[1], \",.2f\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running final scoring on test data\n",
            "114/114 [==============================] - 0s 63us/step\n",
            "The accuracy for this model is  0.91\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ugh-4BRzqDCn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Plot the Training History\n",
        "\n",
        "We store the performance during training is a variable named 'history'. The x-axis is the training time or number of epochs.\n",
        "\n",
        "- Accuracy: Accuracy of the predictions, hopefully this is increasing to near 1.0\n",
        "- Loss: How close the output is to the desired output, this should decrease to near 0.0"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "9351f640-049c-4b95-947b-c378566a1092",
        "id": "pP8zKYNMa4Tj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        }
      },
      "cell_type": "code",
      "source": [
        "# Plot the loss and accuracy curves for training and validation \n",
        "fig, ax = plt.subplots(2,1)\n",
        "\n",
        "ax[0].plot(history.history['acc'], color='b', label=\"Training accuracy\")\n",
        "ax[0].plot(history.history['val_acc'], color='r',label=\"Testing accuracy\")\n",
        "ax[0].set_title(\"Accruacy\")\n",
        "legend = ax[0].legend(loc='best', shadow=True)\n",
        "              \n",
        "ax[1].plot(history.history['loss'], color='b', label=\"Training loss\")\n",
        "ax[1].plot(history.history['val_loss'], color='r', label=\"Testing loss\",axes =ax[1])\n",
        "ax[1].set_title(\"Loss\")\n",
        "legend = ax[1].legend(loc='best', shadow=True)\n",
        "plt.ylim(0,1)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFZCAYAAACv05cWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEsJCCCHEEvn/FYn3kgT+LxQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x396 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "mEuPVnRDdGpu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Section III:  Kaggle Digit Recognition Challenge\n",
        "=== *You must run Section 0 before this section* ===\n",
        "### MNIST hand written digits\n",
        "\n",
        "The MNIST data set is a well known dataset built into the scikit learning library and available in many places.The images are 16x16 pixels so each image has 64 features. \n",
        "\n",
        "### Kaggle Challenges\n",
        "\n",
        "Kaggle,  [www.Kaggle.com](https://www.kaggle.com/), is a website that host many machine learning compeitions, some for large prize money. \n",
        "\n",
        "We will particpate in their[ Digit Recognition Challenge](https://www.kaggle.com/c/digit-recognizer) which is very similar to the MNIST dataset. \n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "wW-_MaeGPeXE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Task 5: Register for Kaggle\n",
        "\n",
        "Create an account at Kaggle,  [www.Kaggle.com](https://www.kaggle.com/). The easiest way to do this is to register with your CSS email address using the \"Sign up with Google\" option, but you are fee to register however you want.\n",
        "\n",
        "### Part 1: Register at Kaggle\n",
        "\n",
        "Once you have registered, post the URL for you account here--you can get there by selecting \"My Account\" under your icon at the top-right after you log in.\n",
        "\n",
        "Student Account:  ____________________\n",
        "\n",
        "### Part 2: Join the Digit Recognition Challenge\n",
        "\n",
        "Once you have registered at Kaggle, you can joint the [Kaggle Digit Recognition challenge](https://www.kaggle.com/c/digit-recognizer). You need to do this to upload submissions which we will do in the next task"
      ]
    },
    {
      "metadata": {
        "id": "tNyw8uV2QWdy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Set up the Input and output\n",
        "\n",
        "Kaggle provides special data for this challenge similar to the MNIST dataset. There is a labeled set of images for training and a unlabeled set of images for submission. Kaggle does not tell you what the sumission images are, but they will score your predictions if you submit them\n",
        "\n",
        "- Training data: 42,000 images, each 28 x28 pixes, each labeled with the actual digit 0 - 9\n",
        "- Submission data: 28,000 images, each 28 x 28 pixes, not labeled. You must generate predictions for each of these\n",
        "\n",
        "**Downloading Kaggle Data: ** Your instructor has already downloaded the challenge data from Kaggle and uploaded it to Github were it is read in below.\n",
        "\n",
        "**Formatting the data: **The data is converted into 28x28 pixel arrays so we can display it\n",
        "\n",
        "### NOTE: This dataset is somewhat large and loading it may take a minute or two \n"
      ]
    },
    {
      "metadata": {
        "id": "p3_nhL0Z_pUh",
        "colab_type": "code",
        "outputId": "970e2eca-9a8d-453c-b59f-14c1624b6c8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "# Read data from the actual Kaggle download files stored in a raw file in GitHub\n",
        "url_kaggle_train = 'https://raw.githubusercontent.com/CIS3115-Machine-Learning-Scholastica/CIS3115ML-Units7and8/master/kaggle-digit-recognizer/train.csv'\n",
        "url_kaggle_test = 'https://raw.githubusercontent.com/CIS3115-Machine-Learning-Scholastica/CIS3115ML-Units7and8/master/kaggle-digit-recognizer/test.csv'\n",
        "  \n",
        "train_kaggle = pd.read_csv(url_kaggle_train)\n",
        "# Pull out the labels or output which are saved in first index\n",
        "y_train_kaggle = train_kaggle.iloc[:,0].values.astype('int32')\n",
        "# Convert remaining values to floats\n",
        "X_train_kaggle = (train_kaggle.iloc[:,1:].values).astype('float32')\n",
        "# Read the kaggle test data which is used for submissions\n",
        "X_submit_kaggle = (pd.read_csv(url_kaggle_test).values).astype('float32')\n",
        "#reshape as 28x28 pixel images\n",
        "X_train_kaggle = X_train_kaggle.reshape(X_train_kaggle.shape[0], 28, 28)\n",
        "X_submit_kaggle = X_submit_kaggle.reshape(X_submit_kaggle.shape[0], 28, 28)\n",
        "\n",
        "print (\"X_train_kaggle training data shape of 28x28 pixels greyscale: \" ,X_train_kaggle.shape)\n",
        "print (\"X_submit_kaggle submission data shape of 28x28 pixels greyscale: : \" ,X_submit_kaggle.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train_kaggle training data shape of 28x28 pixels greyscale:  (42000, 28, 28)\n",
            "X_submit_kaggle submission data shape of 28x28 pixels greyscale: :  (28000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WYyvVxG9En76",
        "colab_type": "code",
        "outputId": "febaf26f-369a-4db7-8f31-71e8daedc0d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        }
      },
      "cell_type": "code",
      "source": [
        "train_kaggle.head(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel0</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel774</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows  785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
              "0      1       0       0       0       0       0       0       0       0   \n",
              "1      0       0       0       0       0       0       0       0       0   \n",
              "2      1       0       0       0       0       0       0       0       0   \n",
              "3      4       0       0       0       0       0       0       0       0   \n",
              "4      0       0       0       0       0       0       0       0       0   \n",
              "\n",
              "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
              "0       0    ...            0         0         0         0         0   \n",
              "1       0    ...            0         0         0         0         0   \n",
              "2       0    ...            0         0         0         0         0   \n",
              "3       0    ...            0         0         0         0         0   \n",
              "4       0    ...            0         0         0         0         0   \n",
              "\n",
              "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
              "0         0         0         0         0         0  \n",
              "1         0         0         0         0         0  \n",
              "2         0         0         0         0         0  \n",
              "3         0         0         0         0         0  \n",
              "4         0         0         0         0         0  \n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "metadata": {
        "id": "tNcdOatyTaQU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Display some sample images\n",
        "\n",
        "This is what a couple of the images look like. This also verifies that your data was read in correctly."
      ]
    },
    {
      "metadata": {
        "id": "0kdUItQ4E2Pc",
        "colab_type": "code",
        "outputId": "53933234-24eb-4dca-d92a-14cf45e2bdd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        }
      },
      "cell_type": "code",
      "source": [
        "for i in range(3, 9):\n",
        "    plt.subplot(330 + (i+1))\n",
        "    plt.imshow(X_train_kaggle[i], cmap=plt.get_cmap('gray'))\n",
        "    plt.title(y_train_kaggle[i]);"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbMAAADvCAYAAAB41jq/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAZJEjldwmcM9AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x396 with 6 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "ChmnrKtoR_lL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Set up the data\n",
        "\n",
        "**Scale Data:** Neural Networks work best with the inputs are between 0 and +1, but the grayscale images have pixel values between 0 and 255. So, each pixel value is divided by 255 to scale it.\n",
        "\n",
        "**Reformatting: **Above we reformatted the data into 28x28 pixel arrays so we could display it. Now we are converting it back to a single list of 784 pixels. ( 28 x 28 = 784)\n",
        "\n",
        "**Split the Data:** The training data is split with 90% used for training and 10% used for testing.\n",
        "\n",
        "**One-Hot Encoding:** A one-hot encoding is a list which is 0 in most positions, and 1 in a single positions.  In this case, the nth digit will be represented as a vector which is 1 in the nth dimension.\n",
        "\n",
        "- For example, 3 would be [0,0,0,1,0,0,0,0,0,0]"
      ]
    },
    {
      "metadata": {
        "id": "2OZWmBNxcvk4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "input_Size = 28 * 28    # images are 28 x 28 pixels or 784 pixels\n",
        "output_Size = 10\n",
        "\n",
        "# Normalize the data so values are between 0 and 1 instead of between 0 and 255\n",
        "X_train_kaggle = X_train_kaggle / 255\n",
        "X_submit_kaggle = X_submit_kaggle / 255\n",
        "\n",
        "#reshape for dense-only inputs\n",
        "train_size = X_train_kaggle.shape[0]\n",
        "submit_size = X_submit_kaggle.shape[0]\n",
        "X_train_kaggle = X_train_kaggle.reshape(train_size, 28 * 28)\n",
        "X_submit_kaggle = X_submit_kaggle.reshape(submit_size, 28 * 28)\n",
        "\n",
        "# Split the data into 80% for training and 10% for testing out the models\n",
        "X_train, X_test, y_train_num, y_test_num = train_test_split(X_train_kaggle, y_train_kaggle, test_size=0.1)\n",
        "\n",
        "# A one-hot encoding is a list which is 0 in most positions, and 1 in a single positions. \n",
        "# In this case, the nth digit will be represented as a vector which is 1 in the nth dimension.\n",
        "# For example, 3 would be [0,0,0,1,0,0,0,0,0,0].\n",
        "y_train = np_utils.to_categorical(y_train_num, output_Size)\n",
        "y_test = np_utils.to_categorical(y_test_num, output_Size)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LPtVA829L2M2",
        "colab_type": "code",
        "outputId": "f9a496de-72e8-49dd-82eb-d037544a78ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "cell_type": "code",
      "source": [
        "print (\"X_train training data shape of 28x28 pixels greyscale: \" ,X_train.shape)\n",
        "print (\"X_test submission data shape of 28x28 pixels greyscale: : \" ,X_test.shape)\n",
        "\n",
        "print (\"y_train training data shape of 28x28 pixels greyscale: \" ,y_train.shape)\n",
        "print (\"y_test submission data shape of 28x28 pixels greyscale: : \" ,y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train training data shape of 28x28 pixels greyscale:  (37800, 784)\n",
            "X_test submission data shape of 28x28 pixels greyscale: :  (4200, 784)\n",
            "y_train training data shape of 28x28 pixels greyscale:  (37800, 10)\n",
            "y_test submission data shape of 28x28 pixels greyscale: :  (4200, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Vhmql7I4GNVu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Neural Network\n",
        "\n",
        "The following code sets up a sequential, four layer neural network. Sequential means that each layer is connected to the layer listed before it:\n",
        "- Input layer: 784 pixels (28x28) used as input values\n",
        "- Hidden layer 1: 20 units using Rectified Linear Units (relu)\n",
        "- Hidden layer 2: 10 units using Rectified Linear Units (relu)\n",
        "- Output  layer: 10 units using softmax to predict the correct digit between 0 and 9\n",
        "---\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "WG4LzWmwJSO6",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Set up the Neural Network\n",
        "input_Size = 28 * 28    # images are 28 x 28 pixels or 784 pixels\n",
        "output_Size = 10\n",
        "\n",
        "Digit_neuralNetwork = Sequential()\n",
        "Digit_neuralNetwork.add(Dense(20, activation='relu', input_dim=(input_Size)))\n",
        "Digit_neuralNetwork.add(Dense(10, activation='relu'))\n",
        "Digit_neuralNetwork.add(Dense(output_Size, activation='softmax'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8eNaL30GUO4X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Compile Neural Network\n",
        "\n",
        "This builds the Neural network. You must specify \n",
        "- optimizer = 'adam' is a common gradient decent method for changing the wieghts during training\n",
        "- loss =  'categorical_crossentropy' is used when you have a number of distinct categories and items can only be in one category.\n",
        "- metrics = 'accuracy' will output the accuracy of the classification, the percent of time the network gets the classification correct"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "xVEAqJ_LJSO_",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Compile neural network model\n",
        "Digit_neuralNetwork.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zTxCMHSfUYQ8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train the Neural Network\n",
        "\n",
        "This will run all 37800 training images through the network and update the weights. \n",
        "\n",
        "- epochs = 10 means to run the training 10 times. \n",
        "- Performance measues:\n",
        " - loss: is a measurement of how far the outputs are from the desired outputs. This should get smaller over time.\n",
        " - acc: is the prediction accuracy as a percent so 0.67 means the model predicts the correct flower 67% of the time. \n",
        " - val_loss: the loss calculated using the testing flowers rather than the training flowers.\n",
        " - val_acc: the accuracy calculated using the testing flowers rather than the training flowers.\n",
        " \n",
        " \n",
        "### Note: This is a large data set and training will be slow. This might take a couple of minutes to run. \n",
        "\n",
        "This is why we are only using 10 epochs initially"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "6c20e658-845e-4c2b-f38c-2ec627a0a0c0",
        "id": "IDrDXDEcJSPE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "cell_type": "code",
      "source": [
        "# Fit model on training data for network with dense input layer\n",
        "\n",
        "history = Digit_neuralNetwork.fit(X_train, y_train,\n",
        "          epochs=10,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 37800 samples, validate on 4200 samples\n",
            "Epoch 1/10\n",
            "37800/37800 [==============================] - 3s 83us/step - loss: 0.5653 - acc: 0.8341 - val_loss: 0.2907 - val_acc: 0.9171\n",
            "Epoch 2/10\n",
            "37800/37800 [==============================] - 2s 57us/step - loss: 0.2527 - acc: 0.9263 - val_loss: 0.2217 - val_acc: 0.9360\n",
            "Epoch 3/10\n",
            "37800/37800 [==============================] - 2s 58us/step - loss: 0.2048 - acc: 0.9417 - val_loss: 0.1983 - val_acc: 0.9448\n",
            "Epoch 4/10\n",
            "37800/37800 [==============================] - 2s 57us/step - loss: 0.1806 - acc: 0.9477 - val_loss: 0.1953 - val_acc: 0.9450\n",
            "Epoch 5/10\n",
            "37800/37800 [==============================] - 2s 57us/step - loss: 0.1637 - acc: 0.9531 - val_loss: 0.1760 - val_acc: 0.9512\n",
            "Epoch 6/10\n",
            "37800/37800 [==============================] - 2s 58us/step - loss: 0.1513 - acc: 0.9556 - val_loss: 0.1657 - val_acc: 0.9531\n",
            "Epoch 7/10\n",
            "37800/37800 [==============================] - 2s 58us/step - loss: 0.1415 - acc: 0.9589 - val_loss: 0.1591 - val_acc: 0.9564\n",
            "Epoch 8/10\n",
            "37800/37800 [==============================] - 2s 57us/step - loss: 0.1327 - acc: 0.9608 - val_loss: 0.1735 - val_acc: 0.9531\n",
            "Epoch 9/10\n",
            "37800/37800 [==============================] - 2s 58us/step - loss: 0.1254 - acc: 0.9637 - val_loss: 0.1634 - val_acc: 0.9540\n",
            "Epoch 10/10\n",
            "37800/37800 [==============================] - 2s 58us/step - loss: 0.1182 - acc: 0.9658 - val_loss: 0.1702 - val_acc: 0.9529\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "1b762b17-c5da-45f1-cb22-3ef1557819af",
        "id": "4ldH06ZhJSPJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "cell_type": "code",
      "source": [
        "# 10. Evaluate model on test data\n",
        "print (\"Running final scoring on test data\")\n",
        "score = Digit_neuralNetwork.evaluate(X_test, y_test, verbose=1)\n",
        "print (\"The accuracy for this model is \", format(score[1], \",.2f\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running final scoring on test data\n",
            "4200/4200 [==============================] - 0s 34us/step\n",
            "The accuracy for this model is  0.95\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KpwB3-bUVVuc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Plot the Training History\n",
        "\n",
        "We store the performance during training is a variable named 'history'. The x-axis is the training time or number of epochs.\n",
        "\n",
        "- Accuracy: Accuracy of the predictions, hopefully this is increasing to near 1.0\n",
        "- Loss: How close the output is to the desired output, this should decrease to near 0.0"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "77c584ce-de13-4411-e090-4f3f89c251c5",
        "id": "_kKSpZEnJSPO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        }
      },
      "cell_type": "code",
      "source": [
        "# Plot the loss and accuracy curves for training and validation \n",
        "fig, ax = plt.subplots(2,1)\n",
        "\n",
        "ax[0].plot(history.history['acc'], color='b', label=\"Training accuracy\")\n",
        "ax[0].plot(history.history['val_acc'], color='r',label=\"Testing accuracy\")\n",
        "ax[0].set_title(\"Accruacy\")\n",
        "legend = ax[0].legend(loc='best', shadow=True)\n",
        "              \n",
        "ax[1].plot(history.history['loss'], color='b', label=\"Training loss\")\n",
        "ax[1].plot(history.history['val_loss'], color='r', label=\"Testing loss\",axes =ax[1])\n",
        "ax[1].set_title(\"Loss\")\n",
        "legend = ax[1].legend(loc='best', shadow=True)\n",
        "plt.ylim(0,1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe0AAAFZCAYAAAC173eYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxyGFwzMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x396 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "xAHcXCEcfzIL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Create the Submission for Kaggle\n",
        "\n",
        "The following code generates a file named CIS3115_Submission.csv which you need to download to your local PC and then upload to [Kaggle's Digit Recognition competition](https://www.kaggle.com/c/digit-recognizer/submit).\n"
      ]
    },
    {
      "metadata": {
        "id": "YqcMfCNsjpOJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predictions = Digit_neuralNetwork.predict_classes(X_submit_kaggle, verbose=0)\n",
        "\n",
        "submissions=pd.DataFrame({\"ImageId\": list(range(1,len(predictions)+1)), \"Label\": predictions})\n",
        "\n",
        "submissions.to_csv(\"CIS3115_Submission.csv\", index=False, header=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d5UGK9BiWDW5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Task 6: First Kaggle Submission\n",
        "\n",
        "Run the code above after training the network above. It will go through the 28,000 submission images and generate an prediction for each. These are saved in a file named \"CIS3115_Submission.csv\"\n",
        "\n",
        "**Colab Users: ** The submission file is stored in the Colab files tied to this colab notebook in the Google cloud. \n",
        "1. Open the left-side menu by clicking on the > icon near the top-left\n",
        "2. Select the file tab\n",
        "3. Hit the Refresh button and the file should be displayed in the list\n",
        "4. Right-click on the file and choose \"Download\" and save it to a folder on your PC.\n",
        "\n",
        "**Juptyter Notebook Users: ** The submission file will be stored in the same folder as your Jupyter notebook file.\n",
        "\n",
        "Once you have the file, return to  the [Kaggle Digit Recognition challenge](https://www.kaggle.com/c/digit-recognizer) and select the Submit button. Follow the steps to upload your submission and see how it scores.\n",
        "\n",
        "Record your initial submission score here: _ _ _ _ _ _ _ _ _ _ _ _\n"
      ]
    },
    {
      "metadata": {
        "id": "e_m4rNNqjfra",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Task 7: Improve you Score\n",
        "\n",
        "Try making changes to your neural network above. Consider more hidden units and more epochs. Try to improve both your training and testing (validation) accuracy.\n",
        "\n",
        "Upload at least one more attemp to  the [Kaggle Digit Recognition challenge](https://www.kaggle.com/c/digit-recognizer).\n",
        "\n",
        "Record your submission scores here:  _ _ _ _ _ _ _ _ _ _\n",
        "\n",
        "\n",
        "### Note: Next week we will study a number of methods to improve your score, so don't be dissapointed if your score this week is low."
      ]
    },
    {
      "metadata": {
        "id": "RUzZntKj1QFz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Wrapping Up\n",
        "\n",
        "Remember to **share this sheet with your instructo**r and submit a link to it in Blackboard."
      ]
    },
    {
      "metadata": {
        "id": "hNmZlPcKWv12",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}