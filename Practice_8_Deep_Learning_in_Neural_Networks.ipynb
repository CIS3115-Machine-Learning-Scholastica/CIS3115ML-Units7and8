{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Practice 8: Deep Learning in Neural Networks.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "KmZ4LSJ7XLR9"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "UcP0RHTjWP1q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Practice 8: Deep Learning in Neural Networks\n",
        "\n",
        "Use this notebook as the starting point for the Practice activities.\n",
        "\n",
        "Student Name:    **[  Put your Name Here ]**\n",
        "\n",
        "\n",
        "## [Video Walkthough of Practice 8.](https://www.youtube.com/watch?v=BSab11nKgIM)\n",
        "\n",
        "## Topics\n",
        "\n",
        "- Reducing the learning rate\n",
        "- Batch size\n",
        "- Random folds, dividing test/train correctly\n",
        "- Overfitting\n",
        "- Saving the best state\n",
        "- Drop out layers"
      ]
    },
    {
      "metadata": {
        "id": "KmZ4LSJ7XLR9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Section 0\n",
        "\n",
        "=== *You must run this section to set up things for any of the sections below * ===\n",
        "### Setting up Python tools\n",
        "\n",
        "\n",
        "\n",
        "We'll use three libraries for this tutorial: \n",
        "- [pandas](http://pandas.pydata.org/) : dataframes for spreadsheet-like data analysis, reading CSV files, time series\n",
        "- [numpy](http://www.numpy.org/) : for multidimensional data and linear algebra tools\n",
        "- [matplotlib](http://matplotlib.org/) : Simple plotting and graphing\n",
        "- [seaborn](http://stanford.edu/~mwaskom/software/seaborn/) : more advanced graphing\n",
        "-  [scikit-learn](https://scikit-learn.org/stable/) : provides many machine learning algorithms and tools to training and test.\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "RHAUKyWlWQ9L",
        "colab_type": "code",
        "outputId": "8e446135-7862-46e8-caae-9fe40be40d04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "# First, we'll import pandas and numpy, two data processing libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# We'll also import seaborn and matplot, twp Python graphing libraries\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "# Import the needed sklearn libraries\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# The Keras library provides support for neural networks and deep learning\n",
        "print (\"====== This should generate a FutureWaring on Conversion ===== ignore this warning\")\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Lambda, Flatten, LSTM\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "from keras.utils import np_utils\n",
        "\n",
        "# We will turn off some warns in this notebook to make it easier to read for new students\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "====== This should generate a FutureWaring on Conversion ===== ignore this warning\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "sTvnB7XwvScZ"
      },
      "cell_type": "markdown",
      "source": [
        "## Task 1: Past Kaggle result for Digit Challenge\n",
        "\n",
        "In an eariler activite you created an account at Kaggle,  [www.Kaggle.com](https://www.kaggle.com/) most likely using your CSS email address with the \"Sign up with Google\" option\n",
        "\n",
        "\n",
        "Return to the [Kaggle Digit Recognition challenge](https://www.kaggle.com/c/digit-recognizer) and find the top score for your submissions--click on the \"My Submissions\" tab. \n",
        "\n",
        "What was your top submission previously:  _ _ _ _ _ _ _ _ _ "
      ]
    },
    {
      "metadata": {
        "id": "mEuPVnRDdGpu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Section 1:  Reducing the Learning Rate\n",
        "=== *You must run Section 0 before this section* ===\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "YZ1dW8lJvScd"
      },
      "cell_type": "markdown",
      "source": [
        "### Set up the Input and output\n",
        "\n",
        "- Training data: 42,000 images, each 28 x28 pixes, each labeled with the actual digit 0 - 9\n",
        "- Submission data: 28,000 images, each 28 x 28 pixes, not labeled. You must generate predictions for each of these\n",
        "\n",
        "### NOTE: This dataset is somewhat large and loading it may take a minute or two \n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "b0d65f3d-104e-439e-d1da-ff8c96422a2b",
        "id": "Z_gd5XuZvScg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "# Read data from the actual Kaggle download files stored in a raw file in GitHub\n",
        "url_kaggle_train = 'https://raw.githubusercontent.com/CIS3115-Machine-Learning-Scholastica/CIS3115ML-Units7and8/master/kaggle-digit-recognizer/train.csv'\n",
        "url_kaggle_test = 'https://raw.githubusercontent.com/CIS3115-Machine-Learning-Scholastica/CIS3115ML-Units7and8/master/kaggle-digit-recognizer/test.csv'\n",
        "  \n",
        "train_kaggle = pd.read_csv(url_kaggle_train)\n",
        "# Pull out the labels or output which are saved in first index\n",
        "y_train_kaggle = train_kaggle.iloc[:,0].values.astype('int32')\n",
        "# Convert remaining values to floats\n",
        "X_train_kaggle = (train_kaggle.iloc[:,1:].values).astype('float32')\n",
        "# Read the kaggle test data which is used for submissions\n",
        "X_submit_kaggle = (pd.read_csv(url_kaggle_test).values).astype('float32')\n",
        "#reshape as 28x28 pixel images\n",
        "X_train_kaggle = X_train_kaggle.reshape(X_train_kaggle.shape[0], 28, 28)\n",
        "X_submit_kaggle = X_submit_kaggle.reshape(X_submit_kaggle.shape[0], 28, 28)\n",
        "\n",
        "print (\"X_train_kaggle training data shape of 28x28 pixels greyscale: \" ,X_train_kaggle.shape)\n",
        "print (\"X_submit_kaggle submission data shape of 28x28 pixels greyscale: : \" ,X_submit_kaggle.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train_kaggle training data shape of 28x28 pixels greyscale:  (42000, 28, 28)\n",
            "X_submit_kaggle submission data shape of 28x28 pixels greyscale: :  (28000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "azNaomGavScs"
      },
      "cell_type": "markdown",
      "source": [
        "## Set up the data\n",
        "\n",
        "**Scale Data:** Neural Networks work best with the inputs are between 0 and +1, but the grayscale images have pixel values between 0 and 255. So, each pixel value is divided by 255 to scale it.\n",
        "\n",
        "**Reformatting: **Above we reformatted the data into 28x28 pixel arrays so we could display it. Now we are converting it back to a single list of 784 pixels. ( 28 x 28 = 784)\n",
        "\n",
        "**Split the Data:** The training data is split with 90% used for training and 10% used for testing.\n",
        "\n",
        "**One-Hot Encoding:** A one-hot encoding is a list which is 0 in most positions, and 1 in a single positions.  In this case, the nth digit will be represented as a vector which is 1 in the nth dimension.\n",
        "\n",
        "- For example, 3 would be [0,0,0,1,0,0,0,0,0,0]"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "eIQ8a0whvScx",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "input_Size = 28 * 28    # images are 28 x 28 pixels or 784 pixels\n",
        "output_Size = 10\n",
        "\n",
        "# Normalize the data so values are between 0 and 1 instead of between 0 and 255\n",
        "X_train_kaggle = X_train_kaggle / 255\n",
        "X_submit_kaggle = X_submit_kaggle / 255\n",
        "\n",
        "#reshape for dense-only inputs\n",
        "train_size = X_train_kaggle.shape[0]\n",
        "submit_size = X_submit_kaggle.shape[0]\n",
        "X_train_kaggle = X_train_kaggle.reshape(train_size, 28 * 28)\n",
        "X_submit_kaggle = X_submit_kaggle.reshape(submit_size, 28 * 28)\n",
        "\n",
        "# Split the data into 80% for training and 10% for testing out the models\n",
        "X_train, X_test, y_train_num, y_test_num = train_test_split(X_train_kaggle, y_train_kaggle, test_size=0.1)\n",
        "\n",
        "# A one-hot encoding is a list which is 0 in most positions, and 1 in a single positions. \n",
        "# In this case, the nth digit will be represented as a vector which is 1 in the nth dimension.\n",
        "# For example, 3 would be [0,0,0,1,0,0,0,0,0,0].\n",
        "y_train = np_utils.to_categorical(y_train_num, output_Size)\n",
        "y_test = np_utils.to_categorical(y_test_num, output_Size)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "c7995cc4-7b2e-4021-d327-c0fa5609edd7",
        "id": "TdY9eRGavSc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "cell_type": "code",
      "source": [
        "print (\"X_train training data shape of 28x28 pixels greyscale: \" ,X_train.shape)\n",
        "print (\"X_test submission data shape of 28x28 pixels greyscale: : \" ,X_test.shape)\n",
        "\n",
        "print (\"y_train training data shape of 28x28 pixels greyscale: \" ,y_train.shape)\n",
        "print (\"y_test submission data shape of 28x28 pixels greyscale: : \" ,y_test.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train training data shape of 28x28 pixels greyscale:  (37800, 784)\n",
            "X_test submission data shape of 28x28 pixels greyscale: :  (4200, 784)\n",
            "y_train training data shape of 28x28 pixels greyscale:  (37800, 10)\n",
            "y_test submission data shape of 28x28 pixels greyscale: :  (4200, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "hwoi3GqJvSdG"
      },
      "cell_type": "markdown",
      "source": [
        "## Neural Network\n",
        "\n",
        "The following code sets up a sequential, four layer neural network. Sequential means that each layer is connected to the layer listed before it:\n",
        "- Input layer: 784 pixels (28x28) used as input values\n",
        "- Hidden layer 1: 20 units using Rectified Linear Units (relu)\n",
        "- Hidden layer 2: 10 units using Rectified Linear Units (relu)\n",
        "- Output  layer: 10 units using softmax to predict the correct digit between 0 and 9\n",
        "---\n"
      ]
    },
    {
      "metadata": {
        "id": "qaV6VT-66iAf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Task 2: Deeper Networks\n",
        "\n",
        "As describe above, the network below has an input layer, 2 hidden layers, and on output layer. Modify the network by adding at least one more hidden layer. Also consider making the hidden layers larger.\n",
        "\n",
        "One possibly configuration would be:\n",
        "\n",
        "```\n",
        "DigitNN = Sequential()\n",
        "DigitNN.add(Dense(50, activation='relu', input_dim=(input_Size)))\n",
        "DigitNN.add(Dense(40, activation='relu'))\n",
        "DigitNN.add(Dense(30, activation='relu'))\n",
        "DigitNN.add(Dense(20, activation='relu'))\n",
        "DigitNN.add(Dense(output_Size, activation='softmax'))\n",
        "```\n",
        "\n",
        "Though you should try your own configuration. We will eventually look at networks of 50+ layers, but for now I suggest you limit yourself to 3-5 hidden layers. \n",
        "\n",
        "\n",
        "*Note: You should not change the input or output layers, they are fixed by our problem definition*\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "M1H9GVNvvSdM",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Set up the Neural Network\n",
        "input_Size = 28 * 28    # images are 28 x 28 pixels or 784 pixels\n",
        "output_Size = 10\n",
        "\n",
        "DigitNN = Sequential()\n",
        "DigitNN.add(Dense(50, activation='relu', input_dim=(input_Size)))\n",
        "DigitNN.add(Dropout(0.2))\n",
        "DigitNN.add(Dense(40, activation='relu'))\n",
        "DigitNN.add(Dropout(0.2))\n",
        "DigitNN.add(Dense(20, activation='relu'))\n",
        "DigitNN.add(Dense(output_Size, activation='softmax'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pJ42A7Pj8bZO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Task 5: Fighting Overfitting (Please do Tasks 3 and 4 below first)\n",
        "\n",
        "When out network gets large enough and our training refined, our network can learn to memorize all the input features. In these cases our prediction accuracy on the training data may reach 100%. But our test accuracy might be lower, say 94%. \n",
        "\n",
        "This is called [Overfitting](https://en.wikipedia.org/wiki/Overfitting). The model has memorized the training data, but not generalize the rules enough to predict new inputs. For more information see [Overfitting in Machine Learning: What It Is and How to Prevent It](https://elitedatascience.com/overfitting-in-machine-learning)\n",
        "\n",
        "The network only learns when there is a mistake between what the model predicts and what it is suppose to predict. If the model is 100% accurate in training, it is not making any mistakes and so not learning or changing the weights at all.\n",
        "\n",
        "One way to prevent overfitting is to introduce some \"noise\" into the training. One way researcher have found helpful is to randomly skip certain weights when updating a neuron. Keras can do this with a [dropout layer](https://keras.io/layers/core/). \n",
        "\n",
        "### Question 1: Do you have Overfitting?\n",
        "\n",
        "After adding more layers to your network and reducing the Learning Rate, does you model overfit the data? That is, does it work really well on the training data, but not so well on the testing data?\n",
        "\n",
        "### Question 2: Try some Dropout layers\n",
        "\n",
        "Add one or more Dropout layers to your network. The following code adds a Dropout layer between two hidden layers that will randomly ignote 50% of the weights each time.\n",
        "\n",
        "```\n",
        "DigitNN.add(Dense(40, activation='relu'))\n",
        "DigitNN.add(Dropout(0.5))\n",
        "DigitNN.add(Dense(30, activation='relu'))\n",
        "```\n",
        "Add one or more Dropout(0.5) layers to your network. Train it and describe how it performs.\n",
        "\n",
        "### Question 3: Try lower Dropout rates\n",
        "\n",
        "Try a lower dropout rate such as, Dropout(0.1), and retrain the network. Describe how it performs.\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "OkBAUTdjvSdc"
      },
      "cell_type": "markdown",
      "source": [
        "## Compile Neural Network\n",
        "\n",
        "This builds the Neural network. You must specify \n",
        "- optimizer = 'adam' is a common gradient decent method for changing the wieghts during training\n",
        "- loss =  'categorical_crossentropy' is used when you have a number of distinct categories and items can only be in one category.\n",
        "- metrics = 'accuracy' will output the accuracy of the classification, the percent of time the network gets the classification correct"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "dWuDYGv6vSdf",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Compile neural network model\n",
        "DigitNN.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "LT2ZSVeXvSdo"
      },
      "cell_type": "markdown",
      "source": [
        "## Train the Neural Network\n",
        "\n",
        "This will run all 37800 training images through the network and update the weights. \n",
        "\n",
        "- epochs = 10 means to run the training 10 times. \n",
        "- Performance measues:\n",
        " - loss: is a measurement of how far the outputs are from the desired outputs. This should get smaller over time.\n",
        " - acc: is the prediction accuracy as a percent so 0.67 means the model predicts the correct flower 67% of the time. \n",
        " - val_loss: the loss calculated using the testing flowers rather than the training flowers.\n",
        " - val_acc: the accuracy calculated using the testing flowers rather than the training flowers.\n",
        " \n",
        " \n",
        "### Note: This is a large data set and training will be slow. This might take a couple of minutes to run. \n",
        "\n",
        "This is why we are only using 10 epochs initially"
      ]
    },
    {
      "metadata": {
        "id": "Zxtu22VA2k-T",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Task 3: Reducing the Learning Rate\n",
        "\n",
        "### Learning Rate\n",
        "\n",
        "The Learning Rate determines how much the weights in a neural network are changed during training. When the Learning Rate is set correctly, the network weights are changed a little bit for each input--in our case for each digit image. These slight adjustments from each digit image allow the network to learn all the weights over a long time.\n",
        "\n",
        "For more on the Learning Rate, see [Understanding Learning Rates and How It Improves Performance in Deep Learning](https://towardsdatascience.com/understanding-learning-rates-and-how-it-improves-performance-in-deep-learning-d0d4059c1c10)\n",
        "\n",
        "### Learning Too Fast\n",
        "If the learning rate is too high, when the network is trained on an image of a \"4\" it may change the weights too much and erase the weight changes for the \"3\". The network will learn too fast causing each new image learned to degrade the performance on past images.  \n",
        "\n",
        "### Learning Too Slow\n",
        "\n",
        "If the Learning Rate is too low, the network is learn very slowly. But long training times can compensate for this, but the network may get stuck in \"local minima\" which are places where any small weight change does not improve the model, but a larger weight change would. \n",
        "\n",
        "Imagine you are in a mountain valley where walking in any direction goes up hill. You may be able to go down hill again if you first go uphill for a short while.\n",
        "![alt text](https://i.stack.imgur.com/rPx0Q.png)\n",
        "\n",
        "### Reducing the Learning Rate over time\n",
        "\n",
        "Keras uses a feature named Callbacks to adjust the learning rate as needed. See the documentation for\n",
        "[ReduceLROnPlateau](https://keras.io/callbacks/#reducelronplateau). Run the code cells below to setup the neural network until you get to Task 2 below where you will implement learning rate reduction\n",
        "\n",
        "The code below defines a callback,  learning_rate_reduction, which will automatically reduce the learning rate at certain times. Answer the following questions using the documentation for\n",
        "[ReduceLROnPlateau](https://keras.io/callbacks/#reducelronplateau). \n",
        "\n",
        "### Question 1: What does the \"patience\" parameter control?\n",
        "\n",
        "### Question 2: How much does the Learning Rate get reduced each time?\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "U-k7Y9H-2wUr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
        " \n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='accuracy', \n",
        "                                            patience=3, \n",
        "                                            verbose=2, \n",
        "                                            factor=0.3, \n",
        "                                            min_lr=0.000001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P2S2jGn338I3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Task 4: Other Callbacks\n",
        "\n",
        "Since we just learned about the ReduceLROnPlateau callback, let's also look at two others that are commonly used.\n",
        "\n",
        "### Question1: What does the [EarlyStopping callback](https://keras.io/callbacks/#earlystopping) do?\n",
        "\n",
        "\n",
        "### Question 2: What does the [ModelCheckpoint callback](https://keras.io/callbacks/#modelcheckpoint) do?\n",
        "\n",
        "### Question 3: Which callbacks are being used? \n",
        "\n",
        "Look at the code two cells below where `DigitNN.fit()` is called. What callbacks are listed to be used when fit() is called?"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "iir-dKffvSd3",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
        "\n",
        "early_stops = EarlyStopping(monitor='accuracy', \n",
        "                            min_delta=0, \n",
        "                            patience=6, \n",
        "                            verbose=2, \n",
        "                            mode='auto')\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath = 'cis3115_MNIST.{epoch:02d}-{accuracy:.6f}.hdf5',\n",
        "                               verbose=2,\n",
        "                               save_best_only=True, \n",
        "                               save_weights_only = True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "18197166-cb1f-45db-fdfe-df9b0f5ccaf7",
        "id": "pMeiCJoZvSd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "cell_type": "code",
      "source": [
        "# Fit model on training data for network with dense input layer\n",
        "\n",
        "history = DigitNN.fit(X_train, y_train,\n",
        "          epochs=10,\n",
        "          verbose=1,\n",
        "          callbacks=[learning_rate_reduction, early_stops],\n",
        "          validation_data=(X_test, y_test))\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 37800 samples, validate on 4200 samples\n",
            "Epoch 1/10\n",
            "37800/37800 [==============================] - 3s 76us/step - loss: 0.6152 - acc: 0.8058 - val_loss: 0.2205 - val_acc: 0.9355\n",
            "Epoch 2/10\n",
            "37800/37800 [==============================] - 3s 67us/step - loss: 0.3032 - acc: 0.9090 - val_loss: 0.1711 - val_acc: 0.9490\n",
            "Epoch 3/10\n",
            "37800/37800 [==============================] - 3s 67us/step - loss: 0.2506 - acc: 0.9246 - val_loss: 0.1569 - val_acc: 0.9519\n",
            "Epoch 4/10\n",
            "37800/37800 [==============================] - 3s 67us/step - loss: 0.2186 - acc: 0.9340 - val_loss: 0.1390 - val_acc: 0.9538\n",
            "Epoch 5/10\n",
            "37800/37800 [==============================] - 3s 67us/step - loss: 0.1981 - acc: 0.9399 - val_loss: 0.1378 - val_acc: 0.9590\n",
            "Epoch 6/10\n",
            "37800/37800 [==============================] - 2s 66us/step - loss: 0.1805 - acc: 0.9450 - val_loss: 0.1345 - val_acc: 0.9588\n",
            "Epoch 7/10\n",
            "37800/37800 [==============================] - 3s 67us/step - loss: 0.1659 - acc: 0.9495 - val_loss: 0.1187 - val_acc: 0.9660\n",
            "Epoch 8/10\n",
            "37800/37800 [==============================] - 3s 67us/step - loss: 0.1561 - acc: 0.9520 - val_loss: 0.1124 - val_acc: 0.9645\n",
            "Epoch 9/10\n",
            "37800/37800 [==============================] - 3s 67us/step - loss: 0.1528 - acc: 0.9524 - val_loss: 0.1174 - val_acc: 0.9643\n",
            "Epoch 10/10\n",
            "37800/37800 [==============================] - 3s 67us/step - loss: 0.1417 - acc: 0.9563 - val_loss: 0.1081 - val_acc: 0.9660\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "J_2GLi6avSeF",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "13b80ce6-3da5-40a9-e056-a940069f3cb5",
        "id": "Y965DSk5vSeJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "cell_type": "code",
      "source": [
        "# 10. Evaluate model on test data\n",
        "print (\"Running final scoring on test data\")\n",
        "score = DigitNN.evaluate(X_test, y_test, verbose=1)\n",
        "print (\"The accuracy for this model is \", format(score[1], \",.2f\"))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running final scoring on test data\n",
            "4200/4200 [==============================] - 0s 30us/step\n",
            "The accuracy for this model is  0.97\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "KJiV__LbvSeO"
      },
      "cell_type": "markdown",
      "source": [
        "## Plot the Training History\n",
        "\n",
        "We store the performance during training is a variable named 'history'. The x-axis is the training time or number of epochs.\n",
        "\n",
        "- Accuracy: Accuracy of the predictions, hopefully this is increasing to near 1.0\n",
        "- Loss: How close the output is to the desired output, this should decrease to near 0.0"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "708b8214-7819-4ae2-a18c-16ee47d8aafd",
        "id": "EsT7FG9SvSeP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        }
      },
      "cell_type": "code",
      "source": [
        "# Plot the loss and accuracy curves for training and validation \n",
        "fig, ax = plt.subplots(2,1)\n",
        "\n",
        "ax[0].plot(history.history['acc'], color='b', label=\"Training accuracy\")\n",
        "ax[0].plot(history.history['val_acc'], color='r',label=\"Testing accuracy\")\n",
        "ax[0].set_title(\"Accruacy\")\n",
        "legend = ax[0].legend(loc='best', shadow=True)\n",
        "              \n",
        "ax[1].plot(history.history['loss'], color='b', label=\"Training loss\")\n",
        "ax[1].plot(history.history['val_loss'], color='r', label=\"Testing loss\",axes =ax[1])\n",
        "ax[1].set_title(\"Loss\")\n",
        "legend = ax[1].legend(loc='best', shadow=True)\n",
        "plt.ylim(0,1)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAFZCAYAAACizedRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEARBEGUGiTNBEARBlBkkzgRBEARRZvw/hdlcJlwZZV4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x396 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "xAHcXCEcfzIL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Section 2: Create the Submission for Kaggle\n",
        "\n",
        "The following code generates a file named CIS3115_Submission.csv which you need to download to your local PC and then upload to [Kaggle's Digit Recognition competition](https://www.kaggle.com/c/digit-recognizer/submit).\n",
        "\n",
        "### Loading and Saving Weights\n",
        "\n",
        "As our networks get more complicated, it will take longer (often hours, if not days) to train them. At certain points you may want to save the weights for the network or load the wieghts. \n",
        "\n",
        "- This code can be used to save the weights of the current model to a file\n",
        "\n",
        "```\n",
        "DigitNN.save_weights('cis3115_model_save_1.hdf5')\n",
        "```\n",
        "\n",
        "- This code can be used to load the weights saved in a file\n",
        "\n",
        "```\n",
        "DigitNN.load_weights('cis3115_model_save_1.hdf5')\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "YqcMfCNsjpOJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predictions = DigitNN.predict_classes(X_submit_kaggle, verbose=0)\n",
        "\n",
        "submissions=pd.DataFrame({\"ImageId\": list(range(1,len(predictions)+1)), \"Label\": predictions})\n",
        "\n",
        "submissions.to_csv(\"CIS3115_Submission.csv\", index=False, header=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d5UGK9BiWDW5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Kaggle Submission\n",
        "\n",
        "Run the code above after training the network above. It will go through the 28,000 submission images and generate an prediction for each. These are saved in a file named \"CIS3115_Submission.csv\"\n",
        "\n",
        "**Colab Users: ** The submission file is stored in the Colab files tied to this colab notebook in the Google cloud. \n",
        "1. Open the left-side menu by clicking on the > icon near the top-left\n",
        "2. Select the file tab\n",
        "3. Hit the Refresh button and the file should be displayed in the list\n",
        "4. Right-click on the file and choose \"Download\" and save it to a folder on your PC.\n",
        "\n",
        "**Juptyter Notebook Users: ** The submission file will be stored in the same folder as your Jupyter notebook file.\n",
        "\n",
        "Once you have the file, return to  the [Kaggle Digit Recognition challenge](https://www.kaggle.com/c/digit-recognizer) and select the Submit button. Follow the steps to upload your submission and see how it scores.\n",
        "\n",
        "Record your initial submission score here: _ _ _ _ _ _ _ _ _ _ _ _\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "cUg7_6I_ui3-"
      },
      "cell_type": "markdown",
      "source": [
        "## Task 7: Report Best Score\n",
        "\n",
        "Try finding a good mix of the following:\n",
        "\n",
        "1. Number and size of hidden layers\n",
        "\n",
        "1. Number and rate of dropout layers\n",
        "\n",
        "1. Learning Rate reduction\n",
        "\n",
        "Submit your best network to the [Kaggle Digit Recognition challenge](https://www.kaggle.com/c/digit-recognizer) and compare it to your original score\n",
        "\n",
        "Original Kaggle scores here:  _ _ _ _ _ _ _ _ _ _\n",
        "Best Kaggle scores here:  _ _ _ _ _ _ _ _ _ _\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "RUzZntKj1QFz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Wrapping Up\n",
        "\n",
        "Remember to **share this sheet with your instructo**r and submit a link to it in Blackboard."
      ]
    },
    {
      "metadata": {
        "id": "hNmZlPcKWv12",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}